<pre class='metadata'>
Title: WebGPU Explainer
Shortname: webgpu-explainer
Level: 1
Status: LS
Group: webgpu
URL: https://gpuweb.github.io/gpuweb/explainer/
Issue Tracking: gpuweb/gpuweb#1321 https://github.com/gpuweb/gpuweb/issues/1321
No Editor: true
No Abstract: true
Markup Shorthands: markdown yes
Markup Shorthands: dfn yes
Markup Shorthands: idl yes
Markup Shorthands: css no
Assume Explicit For: yes
Boilerplate: repository-issue-tracking no
</pre>

Issue(tabatkins/bikeshed#2006): Set up cross-linking into the WebGPU and WGSL specs.


# Motivation # {#motivation}

See [Introduction](https://gpuweb.github.io/gpuweb/#introduction).


# Security/Privacy # {#security}

See [Malicious use considerations](https://gpuweb.github.io/gpuweb/#malicious-use).


# Additional Background # {#background}


## Sandboxed GPU Processes in Web Browsers ## {#gpu-process}

A major design constraint for WebGPU is that it must be implementable and efficient in browsers that use a GPU-process architecture.
GPU drivers need access to additional kernel syscalls than what's otherwise used for Web content, and many GPU drivers are prone to hangs or crashes.
To improve stability and sandboxing, browsers use a special process that contains the GPU driver and talks with the rest of the browser through asynchronous IPC.
GPU processes are (or will be) used in Chromium, Gecko, and WebKit.

GPU processes are less sandboxed than content processes, and they are typically shared between multiple origins.
Therefore, they must validate all messages, for example to prevent a compromised content process from being able to look at the GPU memory used by another content process.
Most of WebGPU's validation rules are necessary to ensure it is secure to use, so all the validation needs to happen in the GPU process.

Likewise, all GPU driver objects only live in the GPU process, including large allocations (like buffers and textures) and complex objects (like pipelines).
In the content process, WebGPU types (`GPUBuffer`, `GPUTexture`, `GPURenderPipeline`, ...) are mostly just "handles" that identify objects that live in the GPU process.
This means that the CPU and GPU memory used by WebGPU object isn't necessarily known in the content process.
A `GPUBuffer` object can use maybe 150 bytes of CPU memory in the content process but hold a 1GB allocation of GPU memory.

See also the description of [the content and device timelines in the specification](https://gpuweb.github.io/gpuweb/#programming-model-timelines).

# JavaScript API # {#api}

## Bitflags ## {#bitflags}

## Object Validity and Destroyed-ness ## {#invalid-and-destroyed}

### WebGPU's Error Monad ### {#error-monad}

A.k.a. Contagious Internal Nullability.
A.k.a. transparent [promise pipelining](http://erights.org/elib/distrib/pipeline.html).

WebGPU is a very chatty API, with some applications making tens of thousands of calls per frame to render complex scenes.
We have seen that the GPU processes needs to validate the commands to satisfy their security property.
To avoid the overhead of validating commands twice in both the GPU and content process, WebGPU is designed so Javascript calls can be forwarded directly to the GPU process and validated there.
See the error section for more details on what's validated where and how errors are reported.

At the same time, during a single frame WebGPU objects can be created that depend on one another.
For example a `GPUCommandBuffer` can be recorded with commands that use temporary `GPUBuffer`s created in the same frame.
In this example, because of the performance constraint of WebGPU, it is not possible to send the message to create the `GPUBuffer` to the GPU process and synchronously wait for its processing before continuing Javascript execution.

Instead, in WebGPU all objects (like `GPUBuffer`) are created immediately on the content timeline and returned to JavaScript.
The validation is almost all done asynchronously on the "device timeline".
In the good case, when no errors occur (validation or out-of-memory), everything looks to JS as if it is synchronous.
However, when an error occurs in a call, it becomes a no-op (aside from error reporting).
If the call returns an object (like `createBuffer`), the object is tagged as "invalid" on the GPU process side.

All WebGPU calls validate that all their arguments are valid objects.
As a result, if a call takes one WebGPU object and returns a new one, the new object is also invalid (hence the term "contagious").

<figure>
    <figcaption>
        Timeline diagram of messages passing between processes, demonstrating how errors are propagated without synchronization.
    </figcaption>
    <object type="image/svg+xml" data="img/error_monad_timeline_diagram.svg"></object>
</figure>

<div class=example>
    Using the API when doing only valid calls looks like a synchronous API:

    <pre highlight="js">
        const srcBuffer = device.createBuffer({
            size: 4,
            usage: GPUBufferUsage.COPY_SRC
        });

        const dstBuffer = ...;

        const encoder = device.createCommandEncoder();
        encoder.copyBufferToBuffer(srcBuffer, 0, dstBuffer, 0, 4);

        const commands = encoder.finish();
        device.queue.submit([commands]);
    </pre>
</div>

<div class=example>
    Errors propagate contagiously when creating objects:

    <pre highlight="js">
        // The size of the buffer is too big, this causes an OOM and srcBuffer is invalid.
        const srcBuffer = device.createBuffer({
            size: BIG_NUMBER,
            usage: GPUBufferUsage.COPY_SRC
        });

        const dstBuffer = ...;

        // The encoder starts as a valid object.
        const encoder = device.createCommandEncoder();
        // Special case: an invalid object is used when encoding commands so the encoder
        // becomes invalid.
        encoder.copyBufferToBuffer(srcBuffer, 0, dstBuffer, 0, 4);

        // commands, the this argument to GPUCommandEncoder.finish is invalid
        // so the call returns an invalid object.
        const commands = encoder.finish();
        // The command references an invalid object so it becomes a noop.
        device.queue.submit([commands]);
    </pre>
</div>

#### Mental Models #### {#error-monad-mental-model}

One way to interpret WebGPU's semantics is that every WebGPU object is actually a `Promise` internally and that all WebGPU methods are `async` and `await` before using each of the WebGPU objects it gets as argument.
However the execution of the async code is outsourced to the GPU process (where it is actually done synchronously).

Another way, closer to actual implementation details, is to imagine that each `GPUFoo` JS object maps to a `gpu::InternalFoo` C++/Rust object on the GPU process that contains a `bool isValid`.
Then during the validation of each command on the GPU process, the `isValid` are all checked and a new, invalid object is returned if validation fails.
On the content process side, the `GPUFoo` implementation doesn't know if the object is valid or not.

### Early Destruction of WebGPU Objects ### {#early-destroy}

Most of the memory usage of WebGPU objects is in the GPU process: it can be GPU memory held by objects like `GPUBuffer` and `GPUTexture`, serialized commands held in CPU memory by `GPURenderBundles`, or complex object graphs for the WGSL AST in `GPUShaderModule`.
The JavaScript garbage collector (GC) is in the renderer process and doesn't know about the memory usage in the GPU process.
Browsers have many heuristics to trigger GCs but a common one is that it should be triggered on memory pressure scenarios.
However a single WebGPU object can hold on to MBs or GBs of memory without the GC knowing and never trigger the memory pressure event.

It is important for WebGPU applications to be able to directly free the memory used by some WebGPU objects without waiting for the GC.
For example applications might create temporary textures and buffers each frame and without the explicit `.destroy()` call they would quickly run out of GPU memory.
That's why WebGPU has a `.destroy()` method on those object types which can hold on to arbitrary amount of memory.
It signals that the application doesn't need the content of the object anymore and that it can be freed as soon as possible.
Of course, it becomes a validation to use the object after the call to `.destroy()`.

<div class=example>
    <pre highlight="js">
        const dstBuffer = device.createBuffer({
            size: 4
            usage: GPUBufferUsage.COPY_DST
        });

        // The buffer is not destroyed (and valid), success!
        device.queue.writeBuffer(dstBuffer, 0, myData);

        buffer.destroy();

        // The buffer is now destroyed, commands using that would use its
        // content produce validation errors.
        device.queue.writeBuffer(dstBuffer, 0, myData);
    </pre>
</div>

Note that, while this looks somewhat similar to the behavior of an invalid buffer, it is distinct.
Unlike invalidity, destroyed-ness can change after creation, is not contagious, and is validated only when work is actually submitted (e.g. `queue.writeBuffer()` or `queue.submit()`), not when creating dependent objects (like command encoders, see above).


## Errors ## {#errors}

In a simple world, error handling in apps would be synchronous with JavaScript exceptions.
However, for multi-process WebGPU implementations, this is prohibitively expensive.

See [[#invalid-and-destroyed]], which also explains how the *browser* handles errors.

### Problems and Solutions ### {#errors-solutions}

Developers and applications need error handling for a number of cases:

- *Debugging*:
    Getting errors synchronously during development, to break in to the debugger.
- *Fatal Errors*:
    Handling device/adapter loss, either by restoring WebGPU or by fallback to non-WebGPU content.
- *Fallible Allocation*:
    Making fallible GPU-memory resource allocations (detecting out-of-memory conditions).
- *Fallible Validation*:
    Checking success of WebGPU calls, for applications' unit/integration testing, WebGPU
    conformance testing, or detecting errors in data-driven applications (e.g. loading glTF
    models that may exceed device limits).
- *Telemetry*:
    Collecting error logs in deployment, for bug reporting and telemetry.

The following sections go into more details on these cases and how they are solved.

#### Debugging #### {#errors-cases-debugging}

**Solution:** Dev Tools.

Implementations should provide a way to enable synchronous validation,
for example via a "break on WebGPU error" option in the developer tools.

This can be achieved with a content-process-gpu-process round-trip in every validated WebGPU
call, though in practice this would be very slow.
It can be optimized by running a second, approximated mirror of the validation steps in the
content process (it will not always have the same results since it cannot immediately know about
out-of-memory errors).

#### Fatal Errors: Adapter and Device Loss #### {#errors-cases-fatalerrors}

**Solution:** [[#device-loss]].

#### Fallible Allocation, Fallible Validation, and Telemetry #### {#errors-cases-other}

**Solution:** *Error Scopes*.

For important context, see [[#invalid-and-destroyed]]. In particular, all errors (validation and
out-of-memory) are detected asynchronously, in a remote process.
In the WebGPU spec, we refer to the thread of work for each WebGPU device as its "device timeline".

As such, applications need a way to instruct the device timeline on what to do with any errors
that occur. To solve this, WebGPU uses *Error Scopes*.

### Error Scopes ### {#errors-errorscopes}

Each device<sup>1</sup> maintains a persistent "error scope" stack state.
Initially, the device's error scope stack is empty.
`GPUDevice.pushErrorScope('validation')` or `GPUDevice.pushErrorScope('out-of-memory')`
begins an error scope and pushes it onto the stack.

`GPUDevice.popErrorScope()` ends an error scope, popping it from the stack and returning a
`Promise<GPUError?>`, which resolves once all enclosed fallible operations have completed and
reported back.
It resolves to `null` if no errors were captured, and otherwise resolves to an object describing
the first error that was captured by the scope - either a `GPUValidationError` or a
`GPUOutOfMemoryError`.

An error scope captures an error if its filter (`'validation'` or `'out-of-memory'`) matches the
type of the error.
This filter mechanism avoids, e.g., accidentally silencing validation errors when trying to
implement fallible allocation.

Any device-timeline error from an operation is passed to the top-most error scope on the stack at
the time it was issued.

- If an error scope captures an error, the error is not passed down the stack.
    Each error scope stores only the **first** error it captures; any further errors it captures
    are **silently ignored**.
- If not, the error is passed down the stack to the enclosing error scope.
- If an error reaches the bottom of the stack, it **may**<sup>2</sup> fire the `uncapturederror`
    event on `GPUDevice`<sup>3</sup> (and could issue a console warning as well).

<sup>1</sup>
In the plan to add multithreading, error scope state to actually be **per-device, per-realm**.
That is, when a GPUDevice is posted to a Worker for the first time, the error scope stack for
that device+realm is always empty.
(If a GPUDevice is copied *back* to an execution context it already existed on, it shares its
error scope state with all other copies on that execution context.)

<sup>2</sup>
The implementation may not choose to always fire the event for a given error, for example if it
has fired too many times, too many times rapidly, or with too many errors of the same kind.
This is similar to how Dev Tools console warnings work today for WebGL.
In poorly-formed applications, this mechanism can prevent the events from having a significant
performance impact on the system.

<sup>3</sup>
More specifically, with multithreading, this event would only exists on the *originating*
`GPUDevice` (the one that came from `createDevice`).
It doesn't exist on `GPUDevice`s produced by sending messages.

```webidl
enum GPUErrorFilter {
    "out-of-memory",
    "validation"
};

interface GPUOutOfMemoryError {
    constructor();
};

interface GPUValidationError {
    constructor(DOMString message);
    readonly attribute DOMString message;
};

typedef (GPUOutOfMemoryError or GPUValidationError) GPUError;

partial interface GPUDevice {
    undefined pushErrorScope(GPUErrorFilter filter);
    Promise<GPUError?> popErrorScope();
};
```

#### How this solves *Fallible Allocation* #### {#errors-errorscopes-allocation}

If a call that fallibly allocates GPU memory (e.g. `createBuffer` or `createTexture`) fails, the
resulting object is invalid (same as if there were a validation error), but an `'out-of-memory'`
error is generated.
An `'out-of-memory'` error scope can be used to detect it.

**Example: tryCreateBuffer**

```ts
async function tryCreateBuffer(device: GPUDevice, descriptor: GPUBufferDescriptor): Promise<GPUBuffer | null> {
  device.pushErrorScope('out-of-memory');
  const buffer = device.createBuffer(descriptor);
  if (await device.popErrorScope() !== null) {
    return null;
  }
  return buffer;
}
```

This interacts with buffer mapping in subtle ways, but they are not explained here.
The principle used to design the interaction is that app code should need to handle as few
different edge cases as possible, so multiple kinds of situations should result in the same
behavior.

#### How this solves *Fallible Validation* #### {#errors-errorscopes-validation}

A `'validation'` error scope can be used to detect validation errors, as above.

**Example: Testing**

```ts
device.pushErrorScope('out-of-memory');
device.pushErrorScope('validation');

{
  // (Do stuff that shouldn't produce errors.)

  {
    device.pushErrorScope('validation');
    device.doOperationThatIsExpectedToError();
    device.popErrorScope().then(error => { assert(error !== null); });
  }

  // (More stuff that shouldn't produce errors.)
}

// Detect unexpected errors.
device.popErrorScope().then(error => { assert(error === null); });
device.popErrorScope().then(error => { assert(error === null); });
```

#### How this solves *Telemetry* #### {#errors-errorscopes-telemetry}

As mentioned above, if an error is not captured by an error scope, it **may** fire the
originating device's `uncapturederror` event.
Applications can either watch for that event, or encapsulate parts of their application with
error scopes, to detect errors for generating error reports.

`uncapturederror` is not strictly necessary to solve this, but has the benefit of providing a
single stream for uncaptured errors from all threads.

#### Error Messages and Debug Labels #### {#errors-errorscopes-labels}

Every WebGPU object has a read-write attribute, `label`, which can be set by the application to
provide information for debugging tools (error messages, native profilers like Xcode, etc.)
Every WebGPU object creation descriptor has a member `label` which sets the initial value of the
attribute.

For both debugging (dev tools messages) and telemetry, implementations can choose to report some
kind of "stack trace" in their error messages, taking advantage of object debug labels.
For example:

```
<myQueue>.submit failed:
- commands[0] (<mainColorPass>) was invalid:
- in setIndexBuffer, indexBuffer (<mesh3.indices>) was invalid:
- in createBuffer, desc.usage was invalid (0x89)
```


## Adapter Selection and Device Init ## {#initialization}


## Adapter and Device Loss ## {#device-loss}

Any situation that prevents further use of a `GPUDevice`, regardless of whether it is caused by a
WebGPU call (e.g. `device.destroy()`, unrecoverable out-of-memory, GPU process crash, or GPU
reset) or happens externally (e.g. GPU unplugged), results in a device loss.

**Design principle:**
There should be as few different-looking error behaviors as possible.
This makes it easier for developers to test their app's behavior in different situations,
improves robustness of applications in the wild, and improves portability between browsers.

Issue: Finish this explainer (see [ErrorHandling.md](https://github.com/gpuweb/gpuweb/blob/main/design/ErrorHandling.md#fatal-errors-requestadapter-requestdevice-and-devicelost)).


## Buffer Mapping ## {#buffer-mapping}


## Multi-Threading ## {#multi-threading}


## Command Encoding and Submission ## {#command-encoding}


## Pipelines ## {#pipelines}


## Image, Video, and Canvas input ## {#image-input}


## Canvas Output ## {#canvas-output}


# WebGPU Shading Language # {#wgsl}
