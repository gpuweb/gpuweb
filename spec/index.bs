<pre class='metadata'>
Title: WebGPU
Shortname: webgpu
Level: 1
Status: w3c/ED
Group: webgpu
URL: https://gpuweb.github.io/gpuweb

!Participate: <a href="https://github.com/gpuweb/gpuweb/issues/new">File an issue</a> (<a href="https://github.com/gpuweb/gpuweb/issues">open issues</a>)

Editor: Dzmitry Malyshau, Mozilla https://www.mozilla.org, dmalyshau@mozilla.com
Editor: Justin Fan, Apple https://www.apple.com, justin_fan@apple.com
Editor: Kai Ninomiya, Google http://www.google.com, kainino@google.com
Abstract: WebGPU exposes an API for performing operations, such as rendering and computation, on a Graphics Processing Unit.
Markup Shorthands: markdown yes
</pre>

<pre class='anchors'>
urlPrefix: https://tc39.github.io/ecma262/; spec: ECMA-262
    type: dfn
        text: realm; url: realm
</pre>


Introduction {#intro}
=====================

This specification rocks.


Type Definitions {#type-definitions}
============================

<script type=idl>
typedef long i32;
typedef unsigned long u32;
typedef unsigned long long u64;
</script>

## Colors and Vectors ## {#colors-and-vectors}

<script type=idl>
dictionary GPUColorDict {
    required double r;
    required double g;
    required double b;
    required double a;
};
typedef (sequence<double> or GPUColorDict) GPUColor;
</script>

Note: `double` is large enough to precisely hold `i32`/`u32`.

<script type=idl>
dictionary GPUOrigin2DDict {
    u32 x = 0;
    u32 y = 0;
};
typedef (sequence<u32> or GPUOrigin2DDict) GPUOrigin2D;
</script>

<script type=idl>
dictionary GPUOrigin3DDict {
    u32 x = 0;
    u32 y = 0;
    u32 z = 0;
};
typedef (sequence<u32> or GPUOrigin3DDict) GPUOrigin3D;
</script>

<script type=idl>
dictionary GPUExtent3DDict {
    required u32 width;
    required u32 height;
    required u32 depth;
};
typedef (sequence<u32> or GPUExtent3DDict) GPUExtent3D;
</script>

## Internal Objects ## {#webgpu-internal-objects}

An <dfn dfn>internal object</dfn> is a non-exposed conceptual WebGPU object.
[=Internal objects=] tracks the state of the object and hold any underlying implementation.
If the state of a particular [=internal object=] can change in parallel from multiple [=realms=],
those changes are always atomic with respect to all [=realms=].

## WebGPU Interfaces ## {#webgpu-interfaces}

A <dfn dfn>WebGPU interface</dfn> is an exposed interface which encapsulates an [=internal object=].
It provides the interface through which the [=internal object=]'s state is changed.

Any interface which includes {{GPUObjectBase}} is a [=WebGPU interface=].

<script type=idl>
interface mixin GPUObjectBase {
    attribute DOMString? label;
};
</script>

<dl dfn-type=attribute dfn-for=GPUObjectBase>
    : <dfn>label</dfn>
    ::

    : <dfn>\[[device]]</dfn>, of type [=device=], readonly
    ::
        An internal slot holding the [=device=] on which the object exists.
</dl>

## Object Descriptors ## {#object-descriptors}

<script type=idl>
dictionary GPUObjectDescriptorBase {
    DOMString? label;
};
</script>


Initialization {#initialization}
================================

<script type=idl>
[Exposed=Window]
partial interface Navigator {
    [SameObject] readonly attribute GPU gpu;
};

[Exposed=DedicatedWorker]
partial interface WorkerNavigator {
    [SameObject] readonly attribute GPU gpu;
};
</script>

<script type=idl>
[Exposed=Window]
interface GPU {
    // May reject with DOMException  // TODO: DOMException("OperationError")?
    Promise<GPUAdapter> requestAdapter(optional GPURequestAdapterOptions options);
};
</script>

## Adapters ## {#adapters}

An <dfn dfn>adapter</dfn> represents an implementation of WebGPU on the system.
Each adapter identifies both an instance of a hardware accelerator (e.g. GPU or CPU) and
an instance of a software implementation of WebGPU on top of that accelerator.

Note:
An [=adapter=] may be a physical display adapter (GPU), but it could also be
a software renderer.
Different [=adapters=] could refer to different implementations on the
same physical adapter (e.g. Vulkan and D3D12),
or to different instances of the same physical configuration
(e.g. if the GPU were disconnected and reconnected).

### GPUAdapter ### {#gpu-adapter}

A <dfn interface>GPUAdapter</dfn> refers to an [=adapter=],
and exposes its capabilities (extensions and limits).

<script type=idl>
interface GPUAdapter {
    readonly attribute DOMString name;
    readonly attribute GPUExtensions extensions;
    //readonly attribute GPULimits limits; Don't expose higher limits for now.

    // May reject with DOMException  // TODO: DOMException("OperationError")?
    Promise<GPUDevice> requestDevice(optional GPUDeviceDescriptor descriptor);
};
</script>

{{GPUAdapter}} has the following attributes:

<dl dfn-type=attribute dfn-for=GPUAdapter>
    : <dfn>\[[adapter]]</dfn>, of type [=adapter=], readonly
    ::
        An internal slot holding the [=adapter=] to which this {{GPUAdapter}}
        refers.

    : <dfn>name</dfn>
    ::
        A human-readable name identifying the adapter.
        The contents are implementation-defined.

    : <dfn>extensions</dfn>
    ::
        A {{GPUExtensions}} object which enumerates the extensions supported
        by the user agent, and whether each extension is supported by the
        underlying implementation.
          - If an extension is not supported by the user agent,
            it will not be present in the object.
          - If an extension is supported by the user agent, but
            not by the [=adapter=], it will be `false`.
          - If an extension is supported by the user agent and
            by the [=adapter=], it will be `true`.
</dl>

### Getting an Adapter ### {#adapter-creation}

To get a {{GPUAdapter}}, use {{GPU/requestAdapter()}}.

<script type=idl>
dictionary GPURequestAdapterOptions {
    GPUPowerPreference powerPreference;
};

enum GPUPowerPreference {
    "low-power",
    "high-performance"
};
</script>

## Devices ## {#devices}

A <dfn dfn>device</dfn> is an arena within which [=internal objects=] are created.
A [=device=] can be shared across multiple [=realms=].
It has the following internal attributes:

<dl dfn-type=attribute dfn-for=device>
    : <dfn>\[[adapter]]</dfn>, of type [=adapter=], readonly
    ::
        The [=adapter=] from which this device was created.
</dl>

When a [=device=] is created, its capabilities are set to those requested by
the user in {{GPUAdapter/requestDevice()}} (which must be no greater than the
capabilities specified by the [=adapter=]).
These capabilities are enforced upon the usage of objects on the [=device=],
even if the underlying [=adapter=] can support higher capabilities.

### GPUDevice ### {#gpu-device}

A {{GPUDevice}} refers to a [=device=] and
exposes the capabilities with which the [=device=] was created.
It is the top-level object through which [=WebGPU interfaces=] are created.

<script type=idl>
[Exposed=(Window, Worker), Serializable]
interface GPUDevice : EventTarget {
    readonly attribute GPUExtensions extensions;
    readonly attribute GPULimits limits;
    readonly attribute GPUAdapter adapter;

    GPUBuffer createBuffer(GPUBufferDescriptor descriptor);
    GPUMappedBuffer createBufferMapped(GPUBufferDescriptor descriptor);
    Promise<GPUMappedBuffer> createBufferMappedAsync(GPUBufferDescriptor descriptor);
    GPUTexture createTexture(GPUTextureDescriptor descriptor);
    GPUSampler createSampler(optional GPUSamplerDescriptor descriptor);

    GPUBindGroupLayout createBindGroupLayout(GPUBindGroupLayoutDescriptor descriptor);
    GPUPipelineLayout createPipelineLayout(GPUPipelineLayoutDescriptor descriptor);
    GPUBindGroup createBindGroup(GPUBindGroupDescriptor descriptor);

    GPUShaderModule createShaderModule(GPUShaderModuleDescriptor descriptor);
    GPUComputePipeline createComputePipeline(GPUComputePipelineDescriptor descriptor);
    GPURenderPipeline createRenderPipeline(GPURenderPipelineDescriptor descriptor);

    GPUCommandEncoder createCommandEncoder(optional GPUCommandEncoderDescriptor descriptor);
    GPURenderBundleEncoder createRenderBundleEncoder(GPURenderBundleEncoderDescriptor descriptor);

    GPUQueue getQueue();
};
GPUDevice includes GPUObjectBase;
</script>

{{GPUDevice}} also has the following internal slots:

<dl dfn-type=attribute dfn-for=GPUDevice>
    : <dfn>\[[device]]</dfn>, of type [=device=], readonly
    ::
        The [=device=] that this {{GPUDevice}} refers to.
</dl>

{{GPUDevice}} objects are [=serializable objects=].

<div algorithm="serializing a GPUDevice">
    Their [=serialization steps=], given |value|, |serialized|, and |forStorage|, are:

    1. If |forStorage| is true, throw a "{{DataCloneError}}".

    1. Set |serialized|.device to the value of |value|.{{GPUDevice/[[device]]}}.
</div>

<div algorithm="deserializing a GPUDevice">
    Their [=deserialization steps=], given |serialized| and |value|, are:

    1. Set |value|.{{GPUDevice/[[device]]}} to |serialized|.device.
</div>

### Getting a Device ### {#device-creation}

To get a {{GPUDevice}}, use {{GPUAdapter/requestDevice()}}.

<script type=idl>
dictionary GPUDeviceDescriptor : GPUObjectDescriptorBase {
    GPUExtensions extensions;
    GPULimits limits;

    // TODO: are other things configurable like queues?
};
</script>

<dl dfn-type=dict-member dfn-for=GPUDeviceDescriptor>
    : <dfn>extensions</dfn>
    ::
        The extensions to request of device creation.

    : <dfn>limits</dfn>
    ::
        The limits to request of device creation.
</dl>

<div algorithm="creating a GPUDevice">
    1. If the requested configuration is not available
        (i.e. the requested extensions or limits cannot be supported),
        {{GPUAdapter/requestDevice()}} rejects with a "{{NotSupportedError}}".

    1. Otherwise, a {{GPUDevice}} is created with the {{GPUExtensions}} and {{GPULimits}} specified.
</div>

<script type=idl>
dictionary GPUExtensions {
    boolean anisotropicFiltering = false;
};
</script>

<script type=idl>
dictionary GPULimits {
    u32 maxBindGroups = 4;
};
</script>


Buffers {#buffers}
==================

## GPUBuffer ## {#buffer}

<script type=idl>
interface GPUBuffer : GPUObjectBase {
    Promise<ArrayBuffer> mapReadAsync();
    Promise<ArrayBuffer> mapWriteAsync();
    void unmap();

    void destroy();
};
</script>

### Creation ### {#buffer-creation}

<script type=idl>
dictionary GPUBufferDescriptor : GPUObjectDescriptorBase {
    required u64 size;
    required GPUBufferUsageFlags usage;
};
</script>

## Buffer Usage ## {#buffer-usage}

<script type=idl>
typedef u32 GPUBufferUsageFlags;
interface GPUBufferUsage {
    const u32 NONE      = 0x0000;
    const u32 MAP_READ  = 0x0001;
    const u32 MAP_WRITE = 0x0002;
    const u32 COPY_SRC  = 0x0004;
    const u32 COPY_DST  = 0x0008;
    const u32 INDEX     = 0x0010;
    const u32 VERTEX    = 0x0020;
    const u32 UNIFORM   = 0x0040;
    const u32 STORAGE   = 0x0080;
    const u32 INDIRECT  = 0x0100;
};
</script>

## Buffer Mapping ## {#buffer-mapping}

<script type=idl>
typedef sequence<any> GPUMappedBuffer;
</script>

{{GPUMappedBuffer}} is always a sequence of 2 elements, of types {{GPUBuffer}}
and {{ArrayBuffer}}, respectively.


Textures {#textures}
====================

## GPUTexture ## {#texture}

<script type=idl>
interface GPUTexture : GPUObjectBase {
    GPUTextureView createView(optional GPUTextureViewDescriptor descriptor);

    void destroy();
};
</script>

### Texture Creation ### {#texture-creation}

<script type=idl>
dictionary GPUTextureDescriptor : GPUObjectDescriptorBase {
    required GPUExtent3D size;
    u32 arrayLayerCount = 1;
    u32 mipLevelCount = 1;
    u32 sampleCount = 1;
    GPUTextureDimension dimension = "2d";
    required GPUTextureFormat format;
    required GPUTextureUsageFlags usage;
};
</script>

<script type=idl>
enum GPUTextureDimension {
    "1d",
    "2d",
    "3d"
};
</script>

<script type=idl>
typedef u32 GPUTextureUsageFlags;
interface GPUTextureUsage {
    const u32 NONE              = 0x00;
    const u32 COPY_SRC          = 0x01;
    const u32 COPY_DST          = 0x02;
    const u32 SAMPLED           = 0x04;
    const u32 STORAGE           = 0x08;
    const u32 OUTPUT_ATTACHMENT = 0x10;
};
</script>

## GPUTextureView ## {#texture-view}

<script type=idl>
interface GPUTextureView : GPUObjectBase {
};
</script>

### Texture View Creation ### {#texture-view-creation}

<script type=idl>
dictionary GPUTextureViewDescriptor : GPUObjectDescriptorBase {
    GPUTextureFormat format;
    GPUTextureViewDimension dimension;
    GPUTextureAspect aspect = "all";
    u32 baseMipLevel = 0;
    u32 mipLevelCount = 0;
    u32 baseArrayLayer = 0;
    u32 arrayLayerCount = 0;
};
</script>

  * {{GPUTextureViewDescriptor/format}}:
    If unspecified, defaults to the format of the texture.

  * {{GPUTextureViewDescriptor/dimension}}:
    If unspecified, defaults to the dimension of the texture.

  * {{GPUTextureViewDescriptor/mipLevelCount}}:
    If mipLevelCount == 0, the texture view will cover all the mipmap levels starting from baseMipLevel.

  * {{GPUTextureViewDescriptor/arrayLayerCount}}:
    If arrayLayerCount == 0, the texture view will cover all the array layers starting from baseArrayLayer.

<script type=idl>
enum GPUTextureViewDimension {
    "1d",
    "2d",
    "2d-array",
    "cube",
    "cube-array",
    "3d"
};
</script>

<script type=idl>
enum GPUTextureAspect {
    "all",
    "stencil-only",
    "depth-only"
};
</script>

## Texture Formats ## {#texture-formats}

The name of the format specifies the order of components, bits per component,
and data type for the component.

  * `r`, `g`, `b`, `a` = red, green, blue, alpha
  * `unorm` = unsigned normalized
  * `snorm` = signed normalized
  * `uint` = unsigned int
  * `sint` = signed int
  * `float` = floating point

If the format has the `-srgb` suffix, then sRGB gamma compression and
decompression are applied during the reading and writing of color values in the
pixel. Compressed texture formats are provided by extensions. Their naming
should follow the convention here, with the texture name as a prefix. e.g.
`etc2-rgba8unorm`.

<script type=idl>
enum GPUTextureFormat {
    // 8-bit formats
    "r8unorm",
    "r8snorm",
    "r8uint",
    "r8sint",

    // 16-bit formats
    "r16uint",
    "r16sint",
    "r16float",
    "rg8unorm",
    "rg8snorm",
    "rg8uint",
    "rg8sint",

    // 32-bit formats
    "r32uint",
    "r32sint",
    "r32float",
    "rg16uint",
    "rg16sint",
    "rg16float",
    "rgba8unorm",
    "rgba8unorm-srgb",
    "rgba8snorm",
    "rgba8uint",
    "rgba8sint",
    "bgra8unorm",
    "bgra8unorm-srgb",
    // Packed 32-bit formats
    "rgb10a2unorm",
    "rg11b10float",

    // 64-bit formats
    "rg32uint",
    "rg32sint",
    "rg32float",
    "rgba16uint",
    "rgba16sint",
    "rgba16float",

    // 128-bit formats
    "rgba32uint",
    "rgba32sint",
    "rgba32float",

    // Depth and stencil formats
    "depth32float",
    "depth24plus",
    "depth24plus-stencil8"
};
</script>

  * The `depth24plus` family of formats ({{GPUTextureFormat/depth24plus}} and
    {{GPUTextureFormat/depth24plus-stencil8}})
    must have a depth-component precision of
    1 ULP &le; 1 / (2<sup>24</sup>).

    Note: This is unlike the 24-bit unsigned normalized format family typically
    found in native APIs, which has a precision of
    1 ULP = 1 / (2<sup>24</sup> &minus; 1).

<script type=idl>
enum GPUTextureComponentType {
    "float",
    "sint",
    "uint"
};
</script>

Samplers {#samplers}
====================

## GPUSampler ## {#sampler}

<script type=idl>
interface GPUSampler : GPUObjectBase {
};
</script>

### Creation ### {#sampler-creation}

<script type=idl>
dictionary GPUSamplerDescriptor : GPUObjectDescriptorBase {
    GPUAddressMode addressModeU = "clamp-to-edge";
    GPUAddressMode addressModeV = "clamp-to-edge";
    GPUAddressMode addressModeW = "clamp-to-edge";
    GPUFilterMode magFilter = "nearest";
    GPUFilterMode minFilter = "nearest";
    GPUFilterMode mipmapFilter = "nearest";
    float lodMinClamp = 0;
    float lodMaxClamp = 0xffffffff; // TODO: What should this be? Was Number.MAX_VALUE.
    GPUCompareFunction compare = "never";
};
</script>

<script type=idl>
enum GPUAddressMode {
    "clamp-to-edge",
    "repeat",
    "mirror-repeat"
};
</script>

<script type=idl>
enum GPUFilterMode {
    "nearest",
    "linear"
};
</script>

<script type=idl>
enum GPUCompareFunction {
    "never",
    "less",
    "equal",
    "less-equal",
    "greater",
    "not-equal",
    "greater-equal",
    "always"
};
</script>


Resource Binding {#binding}
===========================

## GPUPipelineLayout ## {#pipeline-layout}

<script type=idl>
interface GPUPipelineLayout : GPUObjectBase {
};
</script>

### Creation ### {#pipeline-layout-creation}

<script type=idl>
dictionary GPUPipelineLayoutDescriptor : GPUObjectDescriptorBase {
    required sequence<GPUBindGroupLayout> bindGroupLayouts;
};
</script>

## GPUBindGroupLayout ## {#bind-group-layout}

<script type=idl>
interface GPUBindGroupLayout : GPUObjectBase {
};
</script>

### Creation ### {#bind-group-layout-creation}

<script type=idl>
dictionary GPUBindGroupLayoutDescriptor : GPUObjectDescriptorBase {
    required sequence<GPUBindGroupLayoutBinding> bindings;
};
</script>

<script type=idl>
dictionary GPUBindGroupLayoutBinding {
    required u32 binding;
    required GPUShaderStageFlags visibility;
    required GPUBindingType type;
    GPUTextureViewDimension textureDimension = "2d";
    GPUTextureComponentType textureComponentType = "float";
    boolean multisampled = false;
    boolean dynamic = false;
};
</script>

  * {{GPUBindGroupLayoutBinding/textureDimension}}:
    For texture bindings only, we need to know the dimensions and
    multi-sampling properties at the layout creation time.

    Note: This allows Metal-based implementations to back the respective bind
    groups with `MTLArgumentBuffer` objects that are more efficient to bind at
    run-time.

  * {{GPUBindGroupLayoutBinding/dynamic}}:
    For uniform, storage and readonly storage buffer, means that the binding
    has a dynamic offset. One offset must be passed to setBindGroup for each
    dynamic binding in increasing order of
    {{GPUBindGroupLayoutBinding/binding}} number.

<script type=idl>
typedef u32 GPUShaderStageFlags;
interface GPUShaderStage {
    const u32 NONE     = 0x0;
    const u32 VERTEX   = 0x1;
    const u32 FRAGMENT = 0x2;
    const u32 COMPUTE  = 0x4;
};
</script>

<script type=idl>
enum GPUBindingType {
    "uniform-buffer",
    "storage-buffer",
    "readonly-storage-buffer",
    "sampler",
    "sampled-texture",
    "storage-texture"
    // TODO: other binding types
};
</script>

## GPUBindGroup ## {#bind-groups}

<script type=idl>
interface GPUBindGroup : GPUObjectBase {
};
</script>

### Bind Group Creation ### {#bind-group-creation}

<script type=idl>
dictionary GPUBindGroupDescriptor : GPUObjectDescriptorBase {
    required GPUBindGroupLayout layout;
    required sequence<GPUBindGroupBinding> bindings;
};
</script>

<script type=idl>
typedef (GPUSampler or GPUTextureView or GPUBufferBinding) GPUBindingResource;

dictionary GPUBindGroupBinding {
    required u32 binding;
    required GPUBindingResource resource;
};
</script>

<script type=idl>
dictionary GPUBufferBinding {
    required GPUBuffer buffer;
    u64 offset = 0;
    u64 size;
};
</script>

  * {{GPUBufferBinding/size}}: If undefined, specifies the range starting at {{GPUBufferBinding/offset}} and ending at the end of the buffer.


Shader Modules {#shader-modules}
================================

## GPUShaderModule ## {#shader-module}

<script type=idl>
interface GPUShaderModule : GPUObjectBase {
};
</script>

### Shader Module Creation ### {#shader-module-creation}

<script type=idl>
typedef (Uint32Array or DOMString) GPUShaderCode;

dictionary GPUShaderModuleDescriptor : GPUObjectDescriptorBase {
    required GPUShaderCode code;
};
</script>

Note: While the choice of shader language is undecided,
`GPUShaderModuleDescriptor` will temporarily accept both text and binary input.


Pipelines {#pipelines}
======================

<script type=idl>
dictionary GPUPipelineDescriptorBase : GPUObjectDescriptorBase {
    required GPUPipelineLayout layout;
};
</script>

<script type=idl>
dictionary GPUProgrammableStageDescriptor {
    required GPUShaderModule module;
    required DOMString entryPoint;
    // TODO: other stuff like specialization constants?
};
</script>

## GPUComputePipeline ## {#compute-pipeline}

<script type=idl>
interface GPUComputePipeline : GPUObjectBase {
};
</script>

### Creation ### {#compute-pipeline-creation}

<script type=idl>
dictionary GPUComputePipelineDescriptor : GPUPipelineDescriptorBase {
    required GPUProgrammableStageDescriptor computeStage;
};
</script>

## GPURenderPipeline ## {#render-pipeline}

<script type=idl>
interface GPURenderPipeline : GPUObjectBase {
};
</script>

### Creation ### {#render-pipeline-creation}

<script type=idl>
dictionary GPURenderPipelineDescriptor : GPUPipelineDescriptorBase {
    required GPUProgrammableStageDescriptor vertexStage;
    GPUProgrammableStageDescriptor fragmentStage;

    required GPUPrimitiveTopology primitiveTopology;
    GPURasterizationStateDescriptor rasterizationState;
    required sequence<GPUColorStateDescriptor> colorStates;
    GPUDepthStencilStateDescriptor depthStencilState;
    required GPUVertexInputDescriptor vertexInput;

    u32 sampleCount = 1;
    u32 sampleMask = 0xFFFFFFFF;
    boolean alphaToCoverageEnabled = false;
    // TODO: other properties
};
</script>

  * {{GPURenderPipelineDescriptor/sampleCount}}: Number of MSAA samples.

### Primitive Topology ### {#primitive-topology}

<script type=idl>
enum GPUPrimitiveTopology {
    "point-list",
    "line-list",
    "line-strip",
    "triangle-list",
    "triangle-strip"
};
</script>

### Rasterization State ### {#rasterization-state}

<script type=idl>
dictionary GPURasterizationStateDescriptor {
    GPUFrontFace frontFace = "ccw";
    GPUCullMode cullMode = "none";

    i32 depthBias = 0;
    float depthBiasSlopeScale = 0;
    float depthBiasClamp = 0;
};
</script>

<script type=idl>
enum GPUFrontFace {
    "ccw",
    "cw"
};
</script>

<script type=idl>
enum GPUCullMode {
    "none",
    "front",
    "back"
};
</script>

### Color State ### {#color-state}

<script type=idl>
dictionary GPUColorStateDescriptor {
    required GPUTextureFormat format;

    GPUBlendDescriptor alphaBlend;
    GPUBlendDescriptor colorBlend;
    GPUColorWriteFlags writeMask = 0xF;  // GPUColorWrite.ALL
};
</script>

<script type=idl>
typedef u32 GPUColorWriteFlags;
interface GPUColorWrite {
    const u32 NONE  = 0x0;
    const u32 RED   = 0x1;
    const u32 GREEN = 0x2;
    const u32 BLUE  = 0x4;
    const u32 ALPHA = 0x8;
    const u32 ALL   = 0xF;
};
</script>

#### Blend State #### {#blend-state}

<script type=idl>
dictionary GPUBlendDescriptor {
    GPUBlendFactor srcFactor = "one";
    GPUBlendFactor dstFactor = "zero";
    GPUBlendOperation operation = "add";
};
</script>

<script type=idl>
enum GPUBlendFactor {
    "zero",
    "one",
    "src-color",
    "one-minus-src-color",
    "src-alpha",
    "one-minus-src-alpha",
    "dst-color",
    "one-minus-dst-color",
    "dst-alpha",
    "one-minus-dst-alpha",
    "src-alpha-saturated",
    "blend-color",
    "one-minus-blend-color"
};
</script>

<script type=idl>
enum GPUBlendOperation {
    "add",
    "subtract",
    "reverse-subtract",
    "min",
    "max"
};
</script>

<script type=idl>
enum GPUStencilOperation {
    "keep",
    "zero",
    "replace",
    "invert",
    "increment-clamp",
    "decrement-clamp",
    "increment-wrap",
    "decrement-wrap"
};
</script>

### Depth/Stencil State ### {#depth-stencil-state}

<script type=idl>
dictionary GPUDepthStencilStateDescriptor {
    required GPUTextureFormat format;

    boolean depthWriteEnabled = false;
    GPUCompareFunction depthCompare = "always";

    required GPUStencilStateFaceDescriptor stencilFront;
    required GPUStencilStateFaceDescriptor stencilBack;

    u32 stencilReadMask = 0xFFFFFFFF;
    u32 stencilWriteMask = 0xFFFFFFFF;
};
</script>

<script type=idl>
dictionary GPUStencilStateFaceDescriptor {
    GPUCompareFunction compare = "always";
    GPUStencilOperation failOp = "keep";
    GPUStencilOperation depthFailOp = "keep";
    GPUStencilOperation passOp = "keep";
};
</script>

### Vertex Input ### {#vertex-input}

<script type=idl>
enum GPUIndexFormat {
    "uint16",
    "uint32"
};
</script>

#### Vertex formats #### {#vertex-formats}

The name of the format specifies the data type of the component, the number of
values, and whether the data is normalized.

  * `uchar` = unsigned 8-bit value
  * `char` = signed 8-bit value
  * `ushort` = unsigned 16-bit value
  * `short` = signed 16-bit value
  * `half` = half-precision 16-bit floating point value
  * `float` = 32-bit floating point value
  * `uint` = unsigned 32-bit integer value
  * `int` = signed 32-bit integer value

If no number of values is given in the name, a single value is provided.
If the format has the `-bgra` suffix, it means the values are arranged as
blue, green, red and alpha values.

<script type=idl>
enum GPUVertexFormat {
    "uchar2",
    "uchar4",
    "char2",
    "char4",
    "uchar2norm",
    "uchar4norm",
    "char2norm",
    "char4norm",
    "ushort2",
    "ushort4",
    "short2",
    "short4",
    "ushort2norm",
    "ushort4norm",
    "short2norm",
    "short4norm",
    "half2",
    "half4",
    "float",
    "float2",
    "float3",
    "float4",
    "uint",
    "uint2",
    "uint3",
    "uint4",
    "int",
    "int2",
    "int3",
    "int4"
};
</script>

<script type=idl>
enum GPUInputStepMode {
    "vertex",
    "instance"
};
</script>

<script type=idl>
dictionary GPUVertexAttributeDescriptor {
    u64 offset = 0;
    required GPUVertexFormat format;
    required u32 shaderLocation;
};
</script>

<script type=idl>
dictionary GPUVertexBufferDescriptor {
    required u64 stride;
    GPUInputStepMode stepMode = "vertex";
    required sequence<GPUVertexAttributeDescriptor> attributeSet;
};
</script>

<script type=idl>
dictionary GPUVertexInputDescriptor {
    GPUIndexFormat indexFormat = "uint32";
    required sequence<GPUVertexBufferDescriptor?> vertexBuffers;
};
</script>


Command Buffers {#command-buffers}
==================================

## GPUCommandBuffer ## {#command-buffer}

<script type=idl>
interface GPUCommandBuffer : GPUObjectBase {
};
</script>

### Creation ### {#command-buffer-creation}

<script type=idl>
dictionary GPUCommandBufferDescriptor : GPUObjectDescriptorBase {
};
</script>


Command Encoding {#command-encoding}
====================================

## GPUCommandEncoder ## {#command-encoder}

<script type=idl>
interface GPUCommandEncoder : GPUObjectBase {
    GPURenderPassEncoder beginRenderPass(GPURenderPassDescriptor descriptor);
    GPUComputePassEncoder beginComputePass(optional GPUComputePassDescriptor descriptor);

    void copyBufferToBuffer(
        GPUBuffer source,
        u64 sourceOffset,
        GPUBuffer destination,
        u64 destinationOffset,
        u64 size);

    void copyBufferToTexture(
        GPUBufferCopyView source,
        GPUTextureCopyView destination,
        GPUExtent3D copySize);

    void copyTextureToBuffer(
        GPUTextureCopyView source,
        GPUBufferCopyView destination,
        GPUExtent3D copySize);

    void copyTextureToTexture(
        GPUTextureCopyView source,
        GPUTextureCopyView destination,
        GPUExtent3D copySize);

    void copyImageBitmapToTexture(
        GPUImageBitmapCopyView source,
        GPUTextureCopyView destination,
        GPUExtent3D copySize);

    void pushDebugGroup(DOMString groupLabel);
    void popDebugGroup();
    void insertDebugMarker(DOMString markerLabel);

    GPUCommandBuffer finish(optional GPUCommandBufferDescriptor descriptor);
};
</script>

  * {{GPUCommandEncoder/copyImageBitmapToTexture()}}:
      * For now, `copySize.z` must be `1`.

### Creation ### {#command-encoder-creation}

<script type=idl>
dictionary GPUCommandEncoderDescriptor : GPUObjectDescriptorBase {
    // TODO: reusability flag?
};
</script>

## Copy Commands ## {#copy-commands}

<script type=idl>
dictionary GPUBufferCopyView {
    required GPUBuffer buffer;
    u64 offset = 0;
    required u32 rowPitch;
    required u32 imageHeight;
};
</script>

<script type=idl>
dictionary GPUTextureCopyView {
    required GPUTexture texture;
    u32 mipLevel = 0;
    u32 arrayLayer = 0;
    GPUOrigin3D origin;
};
</script>

  * {{GPUTextureCopyView/origin}}: If unspecified, defaults to `[0, 0, 0]`.

<script type=idl>
dictionary GPUImageBitmapCopyView {
    required ImageBitmap imageBitmap;
    GPUOrigin2D origin;
};
</script>

  * {{GPUImageBitmapCopyView/origin}}: If unspecified, defaults to `[0, 0]`.

## Programmable Passes ## {#programmable-passes}

<script type=idl>
interface GPUProgrammablePassEncoder : GPUObjectBase {
    void setBindGroup(u32 index, GPUBindGroup bindGroup,
                      optional sequence<u64> dynamicOffsets);

    void pushDebugGroup(DOMString groupLabel);
    void popDebugGroup();
    void insertDebugMarker(DOMString markerLabel);
};
</script>

Compute Passes {#compute-passes}
================================

## GPUComputePassEncoder ## {#compute-pass-encoder}

<script type=idl>
interface GPUComputePassEncoder : GPUProgrammablePassEncoder {
    void setPipeline(GPUComputePipeline pipeline);
    void dispatch(u32 x, optional u32 y = 1, optional u32 z = 1);
    void dispatchIndirect(GPUBuffer indirectBuffer, u64 indirectOffset);

    void endPass();
};
</script>

### Creation ### {#compute-pass-encoder-creation}

<script type=idl>
dictionary GPUComputePassDescriptor : GPUObjectDescriptorBase {
};
</script>

Render Passes {#render-passes}
==============================

## GPURenderPassEncoder ## {#render-pass-encoder}

<script type=idl>
interface GPURenderEncoderBase : GPUProgrammablePassEncoder {
    void setPipeline(GPURenderPipeline pipeline);

    void setIndexBuffer(GPUBuffer buffer, optional u64 offset = 0);
    void setVertexBuffers(u32 startSlot,
                          sequence<GPUBuffer> buffers, sequence<u64> offsets);

    void draw(u32 vertexCount, u32 instanceCount,
              u32 firstVertex, u32 firstInstance);
    void drawIndexed(u32 indexCount, u32 instanceCount,
                     u32 firstIndex, i32 baseVertex, u32 firstInstance);

    void drawIndirect(GPUBuffer indirectBuffer, u64 indirectOffset);
    void drawIndexedIndirect(GPUBuffer indirectBuffer, u64 indirectOffset);
};

interface GPURenderPassEncoder : GPURenderEncoderBase {
    void setViewport(float x, float y,
                     float width, float height,
                     float minDepth, float maxDepth);

    void setScissorRect(u32 x, u32 y, u32 width, u32 height);

    void setBlendColor(GPUColor color);
    void setStencilReference(u32 reference);

    void executeBundles(sequence<GPURenderBundle> bundles);
    void endPass();
};
</script>

  * In indirect draw calls, the base instance field (inside the indirect
    buffer data) must be set to zero.

  * {{GPURenderPassEncoder/setScissorRect()}}:
      * An error is generated if `width` or `height` is not greater than 0.

When a {{GPURenderPassEncoder}} is created, it has the following default state:
  * Viewport:
      * `x, y` = `0.0, 0.0`
      * `width, height` = the dimensions of the pass's render targets
      * `minDepth, maxDepth` = `0.0, 1.0`
  * Scissor rectangle:
      * `x, y` = `0, 0`
      * `width, height` = the dimensions of the pass's render targets

### Creation ### {#render-pass-encoder-creation}

<script type=idl>
dictionary GPURenderPassDescriptor : GPUObjectDescriptorBase {
    required sequence<GPURenderPassColorAttachmentDescriptor> colorAttachments;
    GPURenderPassDepthStencilAttachmentDescriptor depthStencilAttachment;
};
</script>

#### Color Attachments #### {#color-attachments}

<script type=idl>
dictionary GPURenderPassColorAttachmentDescriptor {
    required GPUTextureView attachment;
    GPUTextureView resolveTarget;

    required (GPULoadOp or GPUColor) loadValue;
    required GPUStoreOp storeOp;
};
</script>

#### Depth/Stencil Attachments #### {#depth-stencil-attachments}

<script type=idl>
dictionary GPURenderPassDepthStencilAttachmentDescriptor {
    required GPUTextureView attachment;

    required (GPULoadOp or float) depthLoadValue;
    required GPUStoreOp depthStoreOp;

    required (GPULoadOp or u32) stencilLoadValue;
    required GPUStoreOp stencilStoreOp;
};
</script>

### Load &amp Store Operations ### {#load-and-store-ops}

<script type=idl>
enum GPULoadOp {
    "load"
};
</script>

<script type=idl>
enum GPUStoreOp {
    "store",
    "clear"
};
</script>


Bundles {#bundles}
==================

## GPURenderBundle ## {#render-bundle}

<script type=idl>
interface GPURenderBundle : GPUObjectBase {
};
</script>

### Creation ### {#render-bundle-creation}

<script type=idl>
dictionary GPURenderBundleDescriptor : GPUObjectDescriptorBase {
};
</script>

<script type=idl>
interface GPURenderBundleEncoder : GPURenderEncoderBase {
    GPURenderBundle finish(optional GPURenderBundleDescriptor descriptor);
};
</script>

### Encoding ### {#render-bundle-encoding}

<script type=idl>
dictionary GPURenderBundleEncoderDescriptor : GPUObjectDescriptorBase {
    required sequence<GPUTextureFormat> colorFormats;
    GPUTextureFormat depthStencilFormat;
    u32 sampleCount = 1;
};
</script>


Queues {#queues}
================

<script type=idl>
interface GPUQueue : GPUObjectBase {
    void submit(sequence<GPUCommandBuffer> buffers);

    GPUFence createFence(optional GPUFenceDescriptor descriptor);
    void signal(GPUFence fence, u64 signalValue);
};
</script>

## GPUFence ## {#fence}

<script type=idl>
interface GPUFence : GPUObjectBase {
    u64 getCompletedValue();
    Promise<void> onCompletion(u64 completionValue);
};
</script>

### Creation ### {#fence-creation}

<script type=idl>
dictionary GPUFenceDescriptor : GPUObjectDescriptorBase {
    u64 initialValue = 0;
};
</script>


Canvas Rendering and Swap Chain {#swapchain}
============================================

<script type=idl>
interface GPUCanvasContext {
    GPUSwapChain configureSwapChain(GPUSwapChainDescriptor descriptor);

    Promise<GPUTextureFormat> getSwapChainPreferredFormat(GPUDevice device);
};
</script>

  * {{GPUCanvasContext/configureSwapChain()}}:
    Configures the swap chain for this canvas, and returns a new
    {{GPUSwapChain}} object representing it. Destroys the any swapchain
    previously returned by `configureSwapChain`, including all of the
    textures it has produced.

<script type=idl>
dictionary GPUSwapChainDescriptor : GPUObjectDescriptorBase {
    required GPUDevice device;
    required GPUTextureFormat format;
    GPUTextureUsageFlags usage = 0x10;  // GPUTextureUsage.OUTPUT_ATTACHMENT
};
</script>

<script type=idl>
interface GPUSwapChain : GPUObjectBase {
    GPUTexture getCurrentTexture();
};
</script>


Errors &amp; Debugging {#errors-and-debugging}
==============================================

## Fatal Errors ## {#fatal-errors}

<script type=idl>
interface GPUDeviceLostInfo {
    readonly attribute DOMString message;
};

partial interface GPUDevice {
    readonly attribute Promise<GPUDeviceLostInfo> lost;
};
</script>


## Error Scopes ## {#error-scopes}

<script type=idl>
enum GPUErrorFilter {
    "none",
    "out-of-memory",
    "validation"
};
</script>

<script type=idl>
[
    Constructor()
]
interface GPUOutOfMemoryError {};

[
    Constructor(DOMString message)
]
interface GPUValidationError {
    readonly attribute DOMString message;
};

typedef (GPUOutOfMemoryError or GPUValidationError) GPUError;
</script>

<script type=idl>
partial interface GPUDevice {
    void pushErrorScope(GPUErrorFilter filter);
    Promise<GPUError?> popErrorScope();
};
</script>


## Telemetry ## {#telemetry}

<script type=idl>
[
    Constructor(DOMString type, GPUUncapturedErrorEventInit gpuUncapturedErrorEventInitDict),
    Exposed=Window
]
interface GPUUncapturedErrorEvent : Event {
    readonly attribute GPUError error;
};

dictionary GPUUncapturedErrorEventInit : EventInit {
    required GPUError error;
};
</script>

<script type=idl>
partial interface GPUDevice {
    [Exposed=Window]
    attribute EventHandler onuncapturederror;
};
</script>
