<pre class='metadata'>
Title: WebGPU
Shortname: webgpu
Level: 1
Status: w3c/ED
Group: webgpu
URL: https://gpuweb.github.io/gpuweb

!Participate: <a href="https://github.com/gpuweb/gpuweb/issues/new">File an issue</a> (<a href="https://github.com/gpuweb/gpuweb/issues">open issues</a>)

Editor: Dzmitry Malyshau, Mozilla https://www.mozilla.org, dmalyshau@mozilla.com
Editor: Justin Fan, Apple https://www.apple.com, justin_fan@apple.com
Editor: Kai Ninomiya, Google http://www.google.com, kainino@google.com
Abstract: WebGPU exposes an API for performing operations, such as rendering and computation, on a Graphics Processing Unit.
Markup Shorthands: markdown yes
</pre>


Introduction {#intro}
=====================

This specification rocks.


Type Definitions {#type-definitions}
============================

<script type=idl>
typedef unsigned long GPUFlags;
typedef unsigned long long GPUBufferSize;
</script>

## Colors and Vectors ## {#colors-and-vectors}

<script type=idl>
dictionary GPUColorDict {
    required double r;
    required double g;
    required double b;
    required double a;
};
typedef (sequence<double> or GPUColorDict) GPUColor;
</script>

Note: `double` is large enough to precisely hold 32-bit signed/unsigned
integers and single-precision floats.

<script type=idl>
dictionary GPUOrigin2DDict {
    unsigned long x = 0;
    unsigned long y = 0;
};
typedef (sequence<unsigned long> or GPUOrigin2DDict) GPUOrigin2D;
</script>

<script type=idl>
dictionary GPUOrigin3DDict {
    unsigned long x = 0;
    unsigned long y = 0;
    unsigned long z = 0;
};
typedef (sequence<unsigned long> or GPUOrigin3DDict) GPUOrigin3D;
</script>

<script type=idl>
dictionary GPUExtent3DDict {
    required unsigned long width;
    required unsigned long height;
    required unsigned long depth;
};
typedef (sequence<unsigned long> or GPUExtent3DDict) GPUExtent3D;
</script>

## Base Objects ## {#base-objects}

<script type=idl>
interface mixin GPUObjectBase {
    attribute DOMString? label;
};
</script>

<script type=idl>
dictionary GPUObjectDescriptorBase {
    DOMString? label;
};
</script>


Initialization {#initialization}
================================

<script type=idl>
[Exposed=Window]
partial interface Navigator {
    [SameObject] readonly attribute GPU gpu;
};

[Exposed=DedicatedWorker]
partial interface WorkerNavigator {
    [SameObject] readonly attribute GPU gpu;
};
</script>

## GPUAdapter ## {#adapter}

<script type=idl>
interface GPUAdapter : GPUObjectBase {
    readonly attribute DOMString name;
    readonly attribute GPUExtensions extensions;
    //readonly attribute GPULimits limits; Don't expose higher limits for now.

    // May reject with DOMException  // TODO: DOMException("OperationError")?
    Promise<GPUDevice> requestDevice(optional GPUDeviceDescriptor descriptor);
};
</script>

### Getting an Adapter ### {#adapter-creation}

<script type=idl>
[Exposed=Window]
interface GPU {
    // May reject with DOMException  // TODO: DOMException("OperationError")?
    Promise<GPUAdapter> requestAdapter(optional GPURequestAdapterOptions options);
};
</script>

<script type=idl>
dictionary GPURequestAdapterOptions {
    GPUPowerPreference? powerPreference;
};
</script>

<script type=idl>
enum GPUPowerPreference {
    "low-power",
    "high-performance"
};
</script>

## GPUDevice ## {#device}

<script type=idl>
[Exposed=(Window, Worker)]
interface GPUDevice : EventTarget {
    readonly attribute GPUExtensions extensions;
    readonly attribute GPULimits limits;
    readonly attribute GPUAdapter adapter;

    GPUBuffer createBuffer(GPUBufferDescriptor descriptor);
    GPUMappedBuffer createBufferMapped(GPUBufferDescriptor descriptor);
    Promise<GPUMappedBuffer> createBufferMappedAsync(GPUBufferDescriptor descriptor);
    GPUTexture createTexture(GPUTextureDescriptor descriptor);
    GPUSampler createSampler(optional GPUSamplerDescriptor descriptor);

    GPUBindGroupLayout createBindGroupLayout(GPUBindGroupLayoutDescriptor descriptor);
    GPUPipelineLayout createPipelineLayout(GPUPipelineLayoutDescriptor descriptor);
    GPUBindGroup createBindGroup(GPUBindGroupDescriptor descriptor);

    GPUShaderModule createShaderModule(GPUShaderModuleDescriptor descriptor);
    GPUComputePipeline createComputePipeline(GPUComputePipelineDescriptor descriptor);
    GPURenderPipeline createRenderPipeline(GPURenderPipelineDescriptor descriptor);

    GPUCommandEncoder createCommandEncoder(optional GPUCommandEncoderDescriptor descriptor);
    GPURenderBundleEncoder createRenderBundleEncoder(GPURenderBundleEncoderDescriptor descriptor);

    GPUQueue getQueue();
};
GPUDevice includes GPUObjectBase;
</script>

### Creation ### {#device-creation}

<script type=idl>
dictionary GPUDeviceDescriptor : GPUObjectDescriptorBase {
    GPUExtensions extensions;
    GPULimits limits;

    // TODO: are other things configurable like queues?
};
</script>

<script type=idl>
dictionary GPUExtensions {
    boolean anisotropicFiltering = false;
};
</script>

<script type=idl>
dictionary GPULimits {
    unsigned long maxBindGroups = 4;
};
</script>


Buffers {#buffers}
==================

## GPUBuffer ## {#buffer}

<script type=idl>
interface GPUBuffer : GPUObjectBase {
    Promise<ArrayBuffer> mapReadAsync();
    Promise<ArrayBuffer> mapWriteAsync();
    void unmap();

    void destroy();
};
</script>

### Creation ### {#buffer-creation}

<script type=idl>
dictionary GPUBufferDescriptor : GPUObjectDescriptorBase {
    required GPUBufferSize size;
    required GPUBufferUsageFlags usage;
};
</script>

## Buffer Usage ## {#buffer-usage}

<script type=idl>
typedef GPUFlags GPUBufferUsageFlags;
interface GPUBufferUsage {
    const GPUFlags NONE      = 0x0000;
    const GPUFlags MAP_READ  = 0x0001;
    const GPUFlags MAP_WRITE = 0x0002;
    const GPUFlags COPY_SRC  = 0x0004;
    const GPUFlags COPY_DST  = 0x0008;
    const GPUFlags INDEX     = 0x0010;
    const GPUFlags VERTEX    = 0x0020;
    const GPUFlags UNIFORM   = 0x0040;
    const GPUFlags STORAGE   = 0x0080;
    const GPUFlags INDIRECT  = 0x0100;
};
</script>

## Buffer Mapping ## {#buffer-mapping}

<script type=idl>
typedef sequence<any> GPUMappedBuffer;
</script>

{{GPUMappedBuffer}} is always a sequence of 2 elements, of types {{GPUBuffer}}
and {{ArrayBuffer}}, respectively.


Textures {#textures}
====================

## GPUTexture ## {#texture}

<script type=idl>
interface GPUTexture : GPUObjectBase {
    GPUTextureView createView(optional GPUTextureViewDescriptor descriptor);

    void destroy();
};
</script>

### Texture Creation ### {#texture-creation}

<script type=idl>
dictionary GPUTextureDescriptor : GPUObjectDescriptorBase {
    required GPUExtent3D size;
    unsigned long arrayLayerCount = 1;
    unsigned long mipLevelCount = 1;
    unsigned long sampleCount = 1;
    GPUTextureDimension dimension = "2d";
    required GPUTextureFormat format;
    required GPUTextureUsageFlags usage;
};
</script>

<script type=idl>
enum GPUTextureDimension {
    "1d",
    "2d",
    "3d"
};
</script>

<script type=idl>
typedef GPUFlags GPUTextureUsageFlags;
interface GPUTextureUsage {
    const GPUFlags NONE              = 0x00;
    const GPUFlags COPY_SRC          = 0x01;
    const GPUFlags COPY_DST          = 0x02;
    const GPUFlags SAMPLED           = 0x04;
    const GPUFlags STORAGE           = 0x08;
    const GPUFlags OUTPUT_ATTACHMENT = 0x10;
};
</script>

## GPUTextureView ## {#texture-view}

<script type=idl>
interface GPUTextureView : GPUObjectBase {
};
</script>

### Texture View Creation ### {#texture-view-creation}

<script type=idl>
dictionary GPUTextureViewDescriptor : GPUObjectDescriptorBase {
    GPUTextureFormat format;
    GPUTextureViewDimension dimension;
    GPUTextureAspect aspect = "all";
    unsigned long baseMipLevel = 0;
    unsigned long mipLevelCount = 0;
    unsigned long baseArrayLayer = 0;
    unsigned long arrayLayerCount = 0;
};
</script>

  * {{GPUTextureViewDescriptor/format}}:
    If unspecified, defaults to the format of the texture.

  * {{GPUTextureViewDescriptor/dimension}}:
    If unspecified, defaults to the dimension of the texture.

  * {{GPUTextureViewDescriptor/mipLevelCount}}:
    If mipLevelCount == 0, the texture view will cover all the mipmap levels starting from baseMipLevel.

  * {{GPUTextureViewDescriptor/arrayLayerCount}}:
    If arrayLayerCount == 0, the texture view will cover all the array layers starting from baseArrayLayer.

<script type=idl>
enum GPUTextureViewDimension {
    "1d",
    "2d",
    "2d-array",
    "cube",
    "cube-array",
    "3d"
};
</script>

<script type=idl>
enum GPUTextureAspect {
    "all",
    "stencil-only",
    "depth-only"
};
</script>

## Texture Formats ## {#texture-formats}

The name of the format specifies the order of components, bits per component,
and data type for the component.

  * `r`, `g`, `b`, `a` = red, green, blue, alpha
  * `unorm` = unsigned normalized
  * `snorm` = signed normalized
  * `uint` = unsigned int
  * `sint` = signed int
  * `float` = floating point

If the format has the `-srgb` suffix, then sRGB gamma compression and
decompression are applied during the reading and writing of color values in the
pixel. Compressed texture formats are provided by extensions. Their naming
should follow the convention here, with the texture name as a prefix. e.g.
`etc2-rgba8unorm`.

<script type=idl>
enum GPUTextureFormat {
    // 8-bit formats
    "r8unorm",
    "r8snorm",
    "r8uint",
    "r8sint",

    // 16-bit formats
    "r16uint",
    "r16sint",
    "r16float",
    "rg8unorm",
    "rg8snorm",
    "rg8uint",
    "rg8sint",

    // 32-bit formats
    "r32uint",
    "r32sint",
    "r32float",
    "rg16uint",
    "rg16sint",
    "rg16float",
    "rgba8unorm",
    "rgba8unorm-srgb",
    "rgba8snorm",
    "rgba8uint",
    "rgba8sint",
    "bgra8unorm",
    "bgra8unorm-srgb",
    // Packed 32-bit formats
    "rgb10a2unorm",
    "rg11b10float",

    // 64-bit formats
    "rg32uint",
    "rg32sint",
    "rg32float",
    "rgba16uint",
    "rgba16sint",
    "rgba16float",

    // 128-bit formats
    "rgba32uint",
    "rgba32sint",
    "rgba32float",

    // Depth and stencil formats
    "depth32float",
    "depth24plus",
    "depth24plus-stencil8"
};
</script>

  * The `depth24plus` family of formats ({{GPUTextureFormat/depth24plus}} and
    {{GPUTextureFormat/depth24plus-stencil8}})
    must have a depth-component precision of
    1 ULP &le; 1 / (2<sup>24</sup>).

    Note: This is unlike the 24-bit unsigned normalized format family typically
    found in native APIs, which has a precision of
    1 ULP = 1 / (2<sup>24</sup> &minus; 1).

<script type=idl>
enum GPUTextureComponentType {
    "float",
    "sint",
    "uint"
};
</script>

Samplers {#samplers}
====================

## GPUSampler ## {#sampler}

<script type=idl>
interface GPUSampler : GPUObjectBase {
};
</script>

### Creation ### {#sampler-creation}

<script type=idl>
dictionary GPUSamplerDescriptor : GPUObjectDescriptorBase {
    GPUAddressMode addressModeU = "clamp-to-edge";
    GPUAddressMode addressModeV = "clamp-to-edge";
    GPUAddressMode addressModeW = "clamp-to-edge";
    GPUFilterMode magFilter = "nearest";
    GPUFilterMode minFilter = "nearest";
    GPUFilterMode mipmapFilter = "nearest";
    float lodMinClamp = 0;
    float lodMaxClamp = 0xffffffff; // TODO: What should this be? Was Number.MAX_VALUE.
    GPUCompareFunction compare = "never";
};
</script>

<script type=idl>
enum GPUAddressMode {
    "clamp-to-edge",
    "repeat",
    "mirror-repeat"
};
</script>

<script type=idl>
enum GPUFilterMode {
    "nearest",
    "linear"
};
</script>

<script type=idl>
enum GPUCompareFunction {
    "never",
    "less",
    "equal",
    "less-equal",
    "greater",
    "not-equal",
    "greater-equal",
    "always"
};
</script>


Resource Binding {#binding}
===========================

## GPUPipelineLayout ## {#pipeline-layout}

<script type=idl>
interface GPUPipelineLayout : GPUObjectBase {
};
</script>

### Creation ### {#pipeline-layout-creation}

<script type=idl>
dictionary GPUPipelineLayoutDescriptor : GPUObjectDescriptorBase {
    required sequence<GPUBindGroupLayout> bindGroupLayouts;
};
</script>

## GPUBindGroupLayout ## {#bind-group-layout}

<script type=idl>
interface GPUBindGroupLayout : GPUObjectBase {
};
</script>

### Creation ### {#bind-group-layout-creation}

<script type=idl>
dictionary GPUBindGroupLayoutDescriptor : GPUObjectDescriptorBase {
    required sequence<GPUBindGroupLayoutBinding> bindings;
};
</script>

<script type=idl>
dictionary GPUBindGroupLayoutBinding {
    required unsigned long binding;
    required GPUShaderStageFlags visibility;
    required GPUBindingType type;
    GPUTextureViewDimension textureDimension = "2d";
    GPUTextureComponentType textureComponentType = "float";
    boolean multisampled = false;
    boolean dynamic = false;
};
</script>

  * {{GPUBindGroupLayoutBinding/textureDimension}}:
    For texture bindings only, we need to know the dimensions and
    multi-sampling properties at the layout creation time.

    Note: This allows Metal-based implementations to back the respective bind
    groups with `MTLArgumentBuffer` objects that are more efficient to bind at
    run-time.

  * {{GPUBindGroupLayoutBinding/dynamic}}:
    For uniform, storage and readonly storage buffer, means that the binding
    has a dynamic offset. One offset must be passed to setBindGroup for each
    dynamic binding in increasing order of
    {{GPUBindGroupLayoutBinding/binding}} number.

<script type=idl>
typedef GPUFlags GPUShaderStageFlags;
interface GPUShaderStage {
    const GPUFlags NONE     = 0x0;
    const GPUFlags VERTEX   = 0x1;
    const GPUFlags FRAGMENT = 0x2;
    const GPUFlags COMPUTE  = 0x4;
};
</script>

<script type=idl>
enum GPUBindingType {
    "uniform-buffer",
    "storage-buffer",
    "readonly-storage-buffer",
    "sampler",
    "sampled-texture",
    "storage-texture"
    // TODO: other binding types
};
</script>

## GPUBindGroup ## {#bind-groups}

<script type=idl>
interface GPUBindGroup : GPUObjectBase {
};
</script>

### Bind Group Creation ### {#bind-group-creation}

<script type=idl>
dictionary GPUBindGroupDescriptor : GPUObjectDescriptorBase {
    required GPUBindGroupLayout layout;
    required sequence<GPUBindGroupBinding> bindings;
};
</script>

<script type=idl>
typedef (GPUSampler or GPUTextureView or GPUBufferBinding) GPUBindingResource;

dictionary GPUBindGroupBinding {
    required unsigned long binding;
    required GPUBindingResource resource;
};
</script>

<script type=idl>
dictionary GPUBufferBinding {
    required GPUBuffer buffer;
    GPUBufferSize offset = 0;
    GPUBufferSize size;
};
</script>

  * {{GPUBufferBinding/size}}: If undefined, specifies the range starting at {{GPUBufferBinding/offset}} and ending at the end of the buffer.


Shader Modules {#shader-modules}
================================

## GPUShaderModule ## {#shader-module}

<script type=idl>
interface GPUShaderModule : GPUObjectBase {
};
</script>

### Shader Module Creation ### {#shader-module-creation}

<script type=idl>
typedef (Uint32Array or DOMString) GPUShaderCode;

dictionary GPUShaderModuleDescriptor : GPUObjectDescriptorBase {
    required GPUShaderCode code;
};
</script>

Note: While the choice of shader language is undecided,
`GPUShaderModuleDescriptor` will temporarily accept both text and binary input.


Pipelines {#pipelines}
======================

<script type=idl>
dictionary GPUPipelineDescriptorBase : GPUObjectDescriptorBase {
    required GPUPipelineLayout layout;
};
</script>

<script type=idl>
dictionary GPUProgrammableStageDescriptor {
    required GPUShaderModule module;
    required DOMString entryPoint;
    // TODO: other stuff like specialization constants?
};
</script>

## GPUComputePipeline ## {#compute-pipeline}

<script type=idl>
interface GPUComputePipeline : GPUObjectBase {
};
</script>

### Creation ### {#compute-pipeline-creation}

<script type=idl>
dictionary GPUComputePipelineDescriptor : GPUPipelineDescriptorBase {
    required GPUProgrammableStageDescriptor computeStage;
};
</script>

## GPURenderPipeline ## {#render-pipeline}

<script type=idl>
interface GPURenderPipeline : GPUObjectBase {
};
</script>

### Creation ### {#render-pipeline-creation}

<script type=idl>
dictionary GPURenderPipelineDescriptor : GPUPipelineDescriptorBase {
    required GPUProgrammableStageDescriptor vertexStage;
    GPUProgrammableStageDescriptor fragmentStage;

    required GPUPrimitiveTopology primitiveTopology;
    GPURasterizationStateDescriptor rasterizationState;
    required sequence<GPUColorStateDescriptor> colorStates;
    GPUDepthStencilStateDescriptor depthStencilState;
    required GPUVertexInputDescriptor vertexInput;

    unsigned long sampleCount = 1;
    unsigned long sampleMask = 0xFFFFFFFF;
    boolean alphaToCoverageEnabled = false;
    // TODO: other properties
};
</script>

  * {{GPURenderPipelineDescriptor/sampleCount}}: Number of MSAA samples.

### Primitive Topology ### {#primitive-topology}

<script type=idl>
enum GPUPrimitiveTopology {
    "point-list",
    "line-list",
    "line-strip",
    "triangle-list",
    "triangle-strip"
};
</script>

### Rasterization State ### {#rasterization-state}

<script type=idl>
dictionary GPURasterizationStateDescriptor {
    GPUFrontFace frontFace = "ccw";
    GPUCullMode cullMode = "none";

    long depthBias = 0;
    float depthBiasSlopeScale = 0;
    float depthBiasClamp = 0;
};
</script>

<script type=idl>
enum GPUFrontFace {
    "ccw",
    "cw"
};
</script>

<script type=idl>
enum GPUCullMode {
    "none",
    "front",
    "back"
};
</script>

### Color State ### {#color-state}

<script type=idl>
dictionary GPUColorStateDescriptor {
    required GPUTextureFormat format;

    GPUBlendDescriptor alphaBlend;
    GPUBlendDescriptor colorBlend;
    GPUColorWriteFlags writeMask = 0xF;  // GPUColorWrite.ALL
};
</script>

<script type=idl>
typedef GPUFlags GPUColorWriteFlags;
interface GPUColorWrite {
    const GPUFlags NONE  = 0x0;
    const GPUFlags RED   = 0x1;
    const GPUFlags GREEN = 0x2;
    const GPUFlags BLUE  = 0x4;
    const GPUFlags ALPHA = 0x8;
    const GPUFlags ALL   = 0xF;
};
</script>

#### Blend State #### {#blend-state}

<script type=idl>
dictionary GPUBlendDescriptor {
    GPUBlendFactor srcFactor = "one";
    GPUBlendFactor dstFactor = "zero";
    GPUBlendOperation operation = "add";
};
</script>

<script type=idl>
enum GPUBlendFactor {
    "zero",
    "one",
    "src-color",
    "one-minus-src-color",
    "src-alpha",
    "one-minus-src-alpha",
    "dst-color",
    "one-minus-dst-color",
    "dst-alpha",
    "one-minus-dst-alpha",
    "src-alpha-saturated",
    "blend-color",
    "one-minus-blend-color"
};
</script>

<script type=idl>
enum GPUBlendOperation {
    "add",
    "subtract",
    "reverse-subtract",
    "min",
    "max"
};
</script>

<script type=idl>
enum GPUStencilOperation {
    "keep",
    "zero",
    "replace",
    "invert",
    "increment-clamp",
    "decrement-clamp",
    "increment-wrap",
    "decrement-wrap"
};
</script>

### Depth/Stencil State ### {#depth-stencil-state}

<script type=idl>
dictionary GPUDepthStencilStateDescriptor {
    required GPUTextureFormat format;

    boolean depthWriteEnabled = false;
    GPUCompareFunction depthCompare = "always";

    required GPUStencilStateFaceDescriptor stencilFront;
    required GPUStencilStateFaceDescriptor stencilBack;

    unsigned long stencilReadMask = 0xFFFFFFFF;
    unsigned long stencilWriteMask = 0xFFFFFFFF;
};
</script>

<script type=idl>
dictionary GPUStencilStateFaceDescriptor {
    GPUCompareFunction compare = "always";
    GPUStencilOperation failOp = "keep";
    GPUStencilOperation depthFailOp = "keep";
    GPUStencilOperation passOp = "keep";
};
</script>

### Vertex Input ### {#vertex-input}

<script type=idl>
enum GPUIndexFormat {
    "uint16",
    "uint32"
};
</script>

#### Vertex formats #### {#vertex-formats}

The name of the format specifies the data type of the component, the number of
values, and whether the data is normalized.

  * `uchar` = unsigned 8-bit value
  * `char` = signed 8-bit value
  * `ushort` = unsigned 16-bit value
  * `short` = signed 16-bit value
  * `half` = half-precision 16-bit floating point value
  * `float` = 32-bit floating point value
  * `uint` = unsigned 32-bit integer value
  * `int` = signed 32-bit integer value

If no number of values is given in the name, a single value is provided.
If the format has the `-bgra` suffix, it means the values are arranged as
blue, green, red and alpha values.

<script type=idl>
enum GPUVertexFormat {
    "uchar2",
    "uchar4",
    "char2",
    "char4",
    "uchar2norm",
    "uchar4norm",
    "char2norm",
    "char4norm",
    "ushort2",
    "ushort4",
    "short2",
    "short4",
    "ushort2norm",
    "ushort4norm",
    "short2norm",
    "short4norm",
    "half2",
    "half4",
    "float",
    "float2",
    "float3",
    "float4",
    "uint",
    "uint2",
    "uint3",
    "uint4",
    "int",
    "int2",
    "int3",
    "int4"
};
</script>

<script type=idl>
enum GPUInputStepMode {
    "vertex",
    "instance"
};
</script>

<script type=idl>
dictionary GPUVertexAttributeDescriptor {
    GPUBufferSize offset = 0;
    required GPUVertexFormat format;
    required unsigned long shaderLocation;
};
</script>

<script type=idl>
dictionary GPUVertexBufferDescriptor {
    required GPUBufferSize stride;
    GPUInputStepMode stepMode = "vertex";
    required sequence<GPUVertexAttributeDescriptor> attributeSet;
};
</script>

<script type=idl>
dictionary GPUVertexInputDescriptor {
    GPUIndexFormat indexFormat = "uint32";
    required sequence<GPUVertexBufferDescriptor?> vertexBuffers;
};
</script>


Command Buffers {#command-buffers}
==================================

## GPUCommandBuffer ## {#command-buffer}

<script type=idl>
interface GPUCommandBuffer : GPUObjectBase {
};
</script>

### Creation ### {#command-buffer-creation}

<script type=idl>
dictionary GPUCommandBufferDescriptor : GPUObjectDescriptorBase {
};
</script>


Command Encoding {#command-encoding}
====================================

## GPUCommandEncoder ## {#command-encoder}

<script type=idl>
interface GPUCommandEncoder : GPUObjectBase {
    GPURenderPassEncoder beginRenderPass(GPURenderPassDescriptor descriptor);
    GPUComputePassEncoder beginComputePass(optional GPUComputePassDescriptor descriptor);

    void copyBufferToBuffer(
        GPUBuffer source,
        GPUBufferSize sourceOffset,
        GPUBuffer destination,
        GPUBufferSize destinationOffset,
        GPUBufferSize size);

    void copyBufferToTexture(
        GPUBufferCopyView source,
        GPUTextureCopyView destination,
        GPUExtent3D copySize);

    void copyTextureToBuffer(
        GPUTextureCopyView source,
        GPUBufferCopyView destination,
        GPUExtent3D copySize);

    void copyTextureToTexture(
        GPUTextureCopyView source,
        GPUTextureCopyView destination,
        GPUExtent3D copySize);

    void copyImageBitmapToTexture(
        GPUImageBitmapCopyView source,
        GPUTextureCopyView destination,
        GPUExtent3D copySize);

    void pushDebugGroup(DOMString groupLabel);
    void popDebugGroup();
    void insertDebugMarker(DOMString markerLabel);

    GPUCommandBuffer finish(optional GPUCommandBufferDescriptor descriptor);
};
</script>

  * {{GPUCommandEncoder/copyImageBitmapToTexture()}}:
      * For now, `copySize.z` must be `1`.

### Creation ### {#command-encoder-creation}

<script type=idl>
dictionary GPUCommandEncoderDescriptor : GPUObjectDescriptorBase {
    // TODO: reusability flag?
};
</script>

## Copy Commands ## {#copy-commands}

<script type=idl>
dictionary GPUBufferCopyView {
    required GPUBuffer buffer;
    GPUBufferSize offset = 0;
    required unsigned long rowPitch;
    required unsigned long imageHeight;
};
</script>

<script type=idl>
dictionary GPUTextureCopyView {
    required GPUTexture texture;
    unsigned long mipLevel = 0;
    unsigned long arrayLayer = 0;
    GPUOrigin3D origin;
};
</script>

  * {{GPUTextureCopyView/origin}}: If unspecified, defaults to `[0, 0, 0]`.

<script type=idl>
dictionary GPUImageBitmapCopyView {
    required ImageBitmap imageBitmap;
    GPUOrigin2D origin;
};
</script>

  * {{GPUImageBitmapCopyView/origin}}: If unspecified, defaults to `[0, 0]`.

## Programmable Passes ## {#programmable-passes}

<script type=idl>
interface GPUProgrammablePassEncoder : GPUObjectBase {
    void setBindGroup(unsigned long index, GPUBindGroup bindGroup,
                      optional sequence<GPUBufferSize> dynamicOffsets);

    void pushDebugGroup(DOMString groupLabel);
    void popDebugGroup();
    void insertDebugMarker(DOMString markerLabel);
};
</script>

Compute Passes {#compute-passes}
================================

## GPUComputePassEncoder ## {#compute-pass-encoder}

<script type=idl>
interface GPUComputePassEncoder : GPUProgrammablePassEncoder {
    void setPipeline(GPUComputePipeline pipeline);
    void dispatch(unsigned long x, optional unsigned long y = 1, optional unsigned long z = 1);
    void dispatchIndirect(GPUBuffer indirectBuffer, GPUBufferSize indirectOffset);

    void endPass();
};
</script>

### Creation ### {#compute-pass-encoder-creation}

<script type=idl>
dictionary GPUComputePassDescriptor : GPUObjectDescriptorBase {
};
</script>

Render Passes {#render-passes}
==============================

## GPURenderPassEncoder ## {#render-pass-encoder}

<script type=idl>
interface GPURenderEncoderBase : GPUProgrammablePassEncoder {
    void setPipeline(GPURenderPipeline pipeline);

    void setIndexBuffer(GPUBuffer buffer, optional GPUBufferSize offset = 0);
    void setVertexBuffers(unsigned long startSlot,
                          sequence<GPUBuffer> buffers, sequence<GPUBufferSize> offsets);

    void draw(unsigned long vertexCount, unsigned long instanceCount,
              unsigned long firstVertex, unsigned long firstInstance);
    void drawIndexed(unsigned long indexCount, unsigned long instanceCount,
                     unsigned long firstIndex, long baseVertex, unsigned long firstInstance);

    void drawIndirect(GPUBuffer indirectBuffer, GPUBufferSize indirectOffset);
    void drawIndexedIndirect(GPUBuffer indirectBuffer, GPUBufferSize indirectOffset);
};

interface GPURenderPassEncoder : GPURenderEncoderBase {
    void setViewport(float x, float y,
                     float width, float height,
                     float minDepth, float maxDepth);

    void setScissorRect(unsigned long x, unsigned long y, unsigned long width, unsigned long height);

    void setBlendColor(GPUColor color);
    void setStencilReference(unsigned long reference);

    void executeBundles(sequence<GPURenderBundle> bundles);
    void endPass();
};
</script>

  * In indirect draw calls, the base instance field (inside the indirect
    buffer data) must be set to zero.

  * {{GPURenderPassEncoder/setScissorRect()}}:
      * An error is generated if `width` or `height` is not greater than 0.

When a {{GPURenderPassEncoder}} is created, it has the following default state:
  * Viewport:
      * `x, y` = `0.0, 0.0`
      * `width, height` = the dimensions of the pass's render targets
      * `minDepth, maxDepth` = `0.0, 1.0`
  * Scissor rectangle:
      * `x, y` = `0, 0`
      * `width, height` = the dimensions of the pass's render targets

### Creation ### {#render-pass-encoder-creation}

<script type=idl>
dictionary GPURenderPassDescriptor : GPUObjectDescriptorBase {
    required sequence<GPURenderPassColorAttachmentDescriptor> colorAttachments;
    GPURenderPassDepthStencilAttachmentDescriptor depthStencilAttachment;
};
</script>

#### Color Attachments #### {#color-attachments}

<script type=idl>
dictionary GPURenderPassColorAttachmentDescriptor {
    required GPUTextureView attachment;
    GPUTextureView resolveTarget;

    required (GPULoadOp or GPUColor) loadValue;
    required GPUStoreOp storeOp;
};
</script>

#### Depth/Stencil Attachments #### {#depth-stencil-attachments}

<script type=idl>
dictionary GPURenderPassDepthStencilAttachmentDescriptor {
    required GPUTextureView attachment;

    required (GPULoadOp or float) depthLoadValue;
    required GPUStoreOp depthStoreOp;

    required (GPULoadOp or unsigned long) stencilLoadValue;
    required GPUStoreOp stencilStoreOp;
};
</script>

### Load &amp Store Operations ### {#load-and-store-ops}

<script type=idl>
enum GPULoadOp {
    "load"
};
</script>

<script type=idl>
enum GPUStoreOp {
    "store",
    "clear"
};
</script>


Bundles {#bundles}
==================

## GPURenderBundle ## {#render-bundle}

<script type=idl>
interface GPURenderBundle : GPUObjectBase {
};
</script>

### Creation ### {#render-bundle-creation}

<script type=idl>
dictionary GPURenderBundleDescriptor : GPUObjectDescriptorBase {
};
</script>

<script type=idl>
interface GPURenderBundleEncoder : GPURenderEncoderBase {
    GPURenderBundle finish(optional GPURenderBundleDescriptor descriptor);
};
</script>

### Encoding ### {#render-bundle-encoding}

<script type=idl>
dictionary GPURenderBundleEncoderDescriptor : GPUObjectDescriptorBase {
    required sequence<GPUTextureFormat> colorFormats;
    GPUTextureFormat depthStencilFormat;
    unsigned long sampleCount = 1;
};
</script>


Queues {#queues}
================

<script type=idl>
interface GPUQueue : GPUObjectBase {
    void submit(sequence<GPUCommandBuffer> buffers);

    GPUFence createFence(optional GPUFenceDescriptor descriptor);
    void signal(GPUFence fence, unsigned long long signalValue);
};
</script>

## GPUFence ## {#fence}

<script type=idl>
interface GPUFence : GPUObjectBase {
    unsigned long long getCompletedValue();
    Promise<void> onCompletion(unsigned long long completionValue);
};
</script>

### Creation ### {#fence-creation}

<script type=idl>
dictionary GPUFenceDescriptor : GPUObjectDescriptorBase {
    unsigned long long initialValue = 0;
};
</script>


Canvas Rendering and Swap Chain {#swapchain}
============================================

<script type=idl>
interface GPUCanvasContext {
    // Calling configureSwapChain a second time invalidates the previous one,
    // and all of the textures it’s produced.
    GPUSwapChain configureSwapChain(GPUSwapChainDescriptor descriptor);

    Promise<GPUTextureFormat> getSwapChainPreferredFormat(GPUDevice device);
};
</script>

<script type=idl>
dictionary GPUSwapChainDescriptor : GPUObjectDescriptorBase {
    required GPUDevice device;
    required GPUTextureFormat format;
    GPUTextureUsageFlags usage = 0x10;  // GPUTextureUsage.OUTPUT_ATTACHMENT
};
</script>

<script type=idl>
interface GPUSwapChain : GPUObjectBase {
    GPUTexture getCurrentTexture();
};
</script>


Errors &amp; Debugging {#errors-and-debugging}
==============================================

## Fatal Errors ## {#fatal-errors}

<script type=idl>
interface GPUDeviceLostInfo {
    readonly attribute DOMString message;
};

partial interface GPUDevice {
    readonly attribute Promise<GPUDeviceLostInfo> lost;
};
</script>


## Error Scopes ## {#error-scopes}

<script type=idl>
enum GPUErrorFilter {
    "none",
    "out-of-memory",
    "validation"
};
</script>

<script type=idl>
[
    Constructor()
]
interface GPUOutOfMemoryError {};

[
    Constructor(DOMString message)
]
interface GPUValidationError {
    readonly attribute DOMString message;
};

typedef (GPUOutOfMemoryError or GPUValidationError) GPUError;
</script>

<script type=idl>
partial interface GPUDevice {
    void pushErrorScope(GPUErrorFilter filter);
    Promise<GPUError?> popErrorScope();
};
</script>


## Telemetry ## {#telemetry}

<script type=idl>
[
    Constructor(DOMString type, GPUUncapturedErrorEventInit gpuUncapturedErrorEventInitDict),
    Exposed=Window
]
interface GPUUncapturedErrorEvent : Event {
    readonly attribute GPUError error;
};

dictionary GPUUncapturedErrorEventInit : EventInit {
    required GPUError error;
};
</script>

<script type=idl>
partial interface GPUDevice {
    [Exposed=Window]
    attribute EventHandler onuncapturederror;
};
</script>
