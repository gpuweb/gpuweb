## Conventions ## {#conventions}

### Dot Syntax ### {#dot-syntax}

In this specification, the `.` ("dot") syntax, common in programming languages, is used.
The phrasing "`Foo.Bar`" means "the `Bar` member of the value (or interface) `Foo`."

For example, where `buffer` is a {{GPUBuffer}}, `buffer.[[device]].[[adapter]]` means
"the `[[adapter]]` internal slot of the `[[device]]` internal slot of `buffer`.

### Internal Objects ### {#webgpu-internal-objects}

An <dfn dfn>internal object</dfn> is a conceptual, non-exposed WebGPU object.
[=Internal objects=] track the state of an API object and hold any underlying implementation.
If the state of a particular [=internal object=] can change in parallel from multiple [=agents=],
those changes are always atomic with respect to all [=agents=].

Note: An "[=agent=]" refers to a JavaScript "thread" (i.e. main thread, or Web Worker).

### WebGPU Interfaces ### {#webgpu-interfaces}

A <dfn dfn>WebGPU interface</dfn> is an exposed interface which encapsulates an [=internal object=].
It provides the interface through which the [=internal object=]'s state is changed.

As a matter of convention, if a [=WebGPU interface=] is referred to as [=invalid=],
it means that the [=internal object=] it encapsulates is [=invalid=].

Any interface which includes {{GPUObjectBase}} is a [=WebGPU interface=].

<script type=idl>
interface mixin GPUObjectBase {
    attribute USVString? label;
};
</script>

{{GPUObjectBase}} has the following attributes:

<dl dfn-type=attribute dfn-for=GPUObjectBase>
    : <dfn>label</dfn>
    ::
        A label which can be used by development tools (such as error/warning messages,
        browser developer tools, or platform debugging utilities) to identify the underlying
        [=internal object=] to the developer.
        It has no specified format, and therefore cannot be reliably machine-parsed.

        In any given situation, the user agent may or may not choose to use this label.
</dl>

{{GPUObjectBase}} has the following internal slots:

<dl dfn-type=attribute dfn-for=GPUObjectBase>
    : <dfn>\[[device]]</dfn>, of type [=device=], readonly
    ::
        An internal slot holding the [=device=] which owns the [=internal object=].
</dl>

### Object Descriptors ### {#object-descriptors}

An <dfn dfn>object descriptor</dfn> holds the information needed to create an object,
which is typically done via one of the `create*` methods of {{GPUDevice}}.

<script type=idl>
dictionary GPUObjectDescriptorBase {
    USVString label;
};
</script>

{{GPUObjectDescriptorBase}} has the following members:

<dl dfn-type=dict-member dfn-for=GPUObjectDescriptorBase>
    : <dfn>label</dfn>
    ::
        The initial value of {{GPUObjectBase/label|GPUObjectBase.label}}.
</dl>

## Invalid Internal Objects &amp; Contagious Invalidity ## {#invalidity}

If an object is successfully created, it is <dfn dfn>valid</dfn> at that moment.
An [=internal object=] may be <dfn dfn>invalid</dfn>.
It may become [=invalid=] during its lifetime, but it will never become valid again.

<div class=note>
    [=Invalid=] objects result from a number of situations, including:

      - If there is an error in the creation of an object, it is immediately invalid.
        This can happen, for example, if the [=object descriptor=] doesn't describe a valid
        object, or if there is not enough memory to allocate a [=resource=].
      - If an object is explicitly destroyed (e.g. {{GPUBuffer/destroy()|GPUBuffer.destroy()}}),
        it becomes invalid.
      - If the [=device=] that owns an object is lost, the object becomes invalid.
</div>

## Coordinate Systems ## {#coordinate-systems}

WebGPU's coordinate systems match DirectX and Metal's coordinate systems in a graphics pipeline.
  - Y-axis is up in normalized device coordinate (NDC): point(-1.0, -1.0) in NDC is located at the bottom-left corner of NDC.
    In addition, x and y in NDC should be between -1.0 and 1.0 inclusive, while z in NDC should be between 0.0 and 1.0 inclusive.
    Vertices out of this range in NDC will not introduce any errors, but they will be clipped.
  - Y-axis is down in framebuffer coordinate, viewport coordinate and fragment/pixel coordinate:
    origin(0, 0) is located at the top-left corner in these coordinate systems.
  - Window/present coordinate matches framebuffer coordinate.
  - UV of origin(0, 0) in texture coordinate represents the first texel (the lowest byte) in texture memory.


## Programming Model ## {#programming-model}

### Timelines ### {#programming-model-timelines}

*This section is non-normative.*

A computer system with a user agent at the front-end and GPU at the back-end
has components working on different timelines in parallel:

: <dfn dfn>Content timeline</dfn>
:: Associated with the execution of the Web script.
    It includes calling all methods described by this specification.

: <dfn dfn>Device timeline</dfn>
:: Associated with the GPU device operations
    that are issued by the user agent.
    It includes creation of adapters, devices, and GPU resources
    and state objects, which are typically synchronous operations from the point
    of view of the user agent part that controls the GPU,
    but can live in a separate OS process.

: <dfn dfn>Queue timeline</dfn>
:: Associated with the execution of operations
    on the compute units of the GPU. It includes actual draw, copy,
    and compute jobs that run on the GPU.

In this specification, asynchronous operations are used when the result value
depends on work that happens on any timeline other than the [=Content timeline=].
They are represented by callbacks and promises in JavaScript.

<div class="example">
{{GPUComputePassEncoder/dispatch(x, y, z)|GPUComputePassEncoder.dispatch()}}:

  1. User encodes a `dispatch` command by calling a method of the
    {{GPUComputePassEncoder}} which happens on the [=Content timeline=].
  2. User issues {{GPUQueue/submit(commandBuffers)|GPUQueue.submit()}} that hands over
    the {{GPUCommandBuffer}} to the user agent, which processes it
    on the [=Device timeline=] by calling the OS driver to do a low-level submission.
  3. The submit gets dispatched by the GPU thread scheduler onto the
    actual compute units for execution, which happens on the [=Queue timeline=].

</div>
<div class="example">
{{GPUDevice/createBuffer(descriptor)|GPUDevice.createBuffer()}}:

  1. User fills out a {{GPUBufferDescriptor}} and creates a {{GPUBuffer}} with it,
    which happens on the [=Content timeline=].
  2. User agent creates a low-level buffer on the [=Device timeline=].

</div>
<div class="example">
{{GPUBuffer/mapAsync()|GPUBuffer.mapAsync()}}:

  1. User requests to map a {{GPUBuffer}} on the [=Content timeline=] and
    gets a promise in return.
  2. User agent checks if the buffer is currently used by the GPU
    and makes a reminder to itself to check back when this usage is over.
  3. After the GPU operating on [=Queue timeline=] is done using the buffer,
    the user agent maps it to memory and [=resolves=] the promise.

</div>

### Memory Model ### {#programming-model-memory}

*This section is non-normative.*

Once a {{GPUDevice}} has been obtained during an application initialization routine,
we can describe the <dfn dfn>WebGPU platform</dfn> as consisting of the following layers:
  1. User agent implementing the specification.
  2. Operating system with low-level native API drivers for this device.
  3. Actual CPU and GPU hardware.

Each layer of the [=WebGPU platform=] may have different memory types
that the user agent needs to consider when implementing the specification:
  - The script-owned memory, such as an {{ArrayBuffer}} created by the script,
    is generally not accessible by a GPU driver.
  - A user agent may have different processes responsible for running
    the content and communication to the GPU driver.
    In this case, it uses inter-process shared memory to transfer data.
  - Dedicated GPUs have their own memory with high bandwidth,
    while integrated GPUs typically share memory with the system.

Most [=physical resources=] are allocated in the memory of type
that is efficient for computation or rendering by the GPU.
When the user needs to provide new data to the GPU,
the data may first need to cross the process boundary in order to reach
the user agent part that communicates with the GPU driver.
Then it may need to be made visible to the driver,
which sometimes requires a copy into driver-allocated staging memory.
Finally, it may need to be transferred to the dedicated GPU memory,
potentially changing the internal layout into one
that is most efficient for GPUs to operate on.

All of these transitions are done by the WebGPU implementation of the user agent.

Note: This example describes the worst case, while in practice
the implementation may not need to cross the process boundary,
or may be able to expose the driver-managed memory directly to
the user behind an `ArrayBuffer`, thus avoiding any data copies.

### Multi-Threading ### {#programming-model-multi-threading}

### Resource Usages ### {#programming-model-resource-usage}

Buffers and textures can be used by the GPU in multiple ways,
which can be split into two groups:

: <dfn dfn>Read-only usage</dfn>s
:: Usages like
    {{GPUBufferUsage/VERTEX|GPUBufferUsage.VERTEX}} or
    {{GPUTextureUsage/SAMPLED|GPUTextureUsage.SAMPLED}}
    don't change the contents of a resource.

: <dfn dfn>Mutating usage</dfn>s
:: Usages like {{GPUBufferUsage/STORAGE|GPUBufferUsage.STORAGE}}
    do change the contents of a resource.

Issue(gpuweb/gpuweb#296): Consider merging all read-only usages.

Textures may consist of separate [=mipmap levels=] and [=array layers=],
which can be used differently at any given time.
Each such <dfn dfn>subresource</dfn> is uniquely identified by a
[=texture=], [=mipmap level=], and
(for {{GPUTextureDimension/2d}} textures only) [=array layer=].

The **main usage rule** is that any [=subresource=]
at any given time can only be in either:
  - a combination of [=read-only usage=]s
  - a single [=mutating usage=]

Enforcing this rule allows the API to limit when data races can occur
when working with memory. That property makes applications written against
WebGPU more likely to run without modification on different platforms.

Generally, when an implementation processes an operation that uses a [=subresource=]
in a different way than its current usage allows, it schedules a transition of the resource
into the new state. In some cases, like within an open {{GPURenderPassEncoder}}, such a
transition is impossible due to the hardware limitations.
We define these places as <dfn dfn>usage scopes</dfn>:
each [=subresource=] must not change usage within the [=usage scope=].

For example, binding the same buffer for {{GPUBufferUsage/STORAGE|GPUBufferUsage.STORAGE}} as well as for
{{GPUBufferUsage/VERTEX|GPUBufferUsage.VERTEX}} within the same {{GPURenderPassEncoder}} would put the encoder
as well as the owning {{GPUCommandEncoder}} into the error state. Since
{{GPUBufferUsage/STORAGE|GPUBufferUsage.STORAGE}} is the only [=mutating usage=] for a buffer
that is valid inside a render pass, if it's present,
this buffer can't be used in any other way within this pass.

The [=subresources=] of textures included in the views provided to
{{GPURenderPassColorAttachmentDescriptor/attachment|GPURenderPassColorAttachmentDescriptor.attachment}} and
{{GPURenderPassColorAttachmentDescriptor/resolveTarget|GPURenderPassColorAttachmentDescriptor.resolveTarget}}
are considered to have {{GPUTextureUsage/OUTPUT_ATTACHMENT}}
for the [=usage scope=] of this render pass.

The <dfn dfn>physical size</dfn> of a {{GPUTexture}} [=subresource=] is the dimension of the {{GPUTexture}}
[=subresource=] in texels that includes the possible extra paddings to form complete [=texel blocks=] in the
[=subresource=].

  - For pixel-based {{GPUTextureFormat}}s, the [=physical size=] is always equal to the size of the [=subresource=]
    used in the sampling hardwares.
  - {{GPUTexture}}s in block-based compressed {{GPUTextureFormat}}s always have a [=mipmap level=] 0 whose {{GPUTexture/[[textureSize]]}}
    is a multiple of the [=texel block size=], but the lower mipmap levels might not be the multiple of the [=texel block size=] and can
    have paddings.

<div class="example">
Considering a {{GPUTexture}} in BC format whose {{GPUTexture/[[textureSize]]}} is {60, 60, 1}, when sampling
the {{GPUTexture}} at [=mipmap level=] 2, the sampling hardware uses {15, 15, 1} as the size of the [=subresource=],
while its [=physical size=] is {16, 16, 1} as the block-compression algorithm can only operate on 4x4 [=texel blocks=].
</div>

Issue(gpuweb/gpuweb#514): Document read-only states for depth views.

### Synchronization ### {#programming-model-synchronization}

For each [=subresource=] of a [=physical resource=], its set of
[=usage flags=] is tracked on the [=Queue timeline=].
<dfn dfn>Usage flags</dfn> are {{GPUBufferUsage}} or {{GPUTextureUsage}} flags,
according to the type of the subresource.

Issue: This section will need to be revised to support multiple queues.

On the [=Queue timeline=], there is an ordered sequence of [=usage scopes=].
Each item on the timeline is contained within exactly one scope.
For the duration of each scope, the set of [=usage flags=] of any given
[=subresource=] is constant.
A [=subresource=] may transition to new usages
at the boundaries between [=usage scope=]s.

This specification defines the following [=usage scopes=]:
  1. an individual command on a {{GPUCommandEncoder}}, such as {{GPUCommandEncoder/copyBufferToTexture()|GPUCommandEncoder.copyBufferToTexture}}.
  2. an individual command on a {{GPUComputePassEncoder}}, such as {{GPUProgrammablePassEncoder/setBindGroup(index, bindGroup, dynamicOffsets)|GPUProgrammablePassEncoder.setBindGroup}}.
  3. the whole {{GPURenderPassEncoder}}.

Note: calling {{GPUProgrammablePassEncoder/setBindGroup(index, bindGroup, dynamicOffsets)|GPUProgrammablePassEncoder.setBindGroup}}
adds the {{GPUBindGroup/[[usedBuffers]]}} and {{GPUBindGroup/[[usedTextures]]}} to the [=usage scope=]
regardless of whether the shader or {{GPUPipelineLayout}} actually depends on these bindings.
Similarly {{GPURenderEncoderBase/setIndexBuffer()|GPURenderEncoderBase.setIndexBuffer}}
add the index buffer to the usage scope (as {{GPUBufferUsage/INDEX|GPUBufferUsage.INDEX}})
regardless of whether the indexed draw calls are used afterwards.

The [=usage scopes=] are validated at {{GPUCommandEncoder/finish()|GPUCommandEncoder.finish}} time.
The implementation performs the <dfn dfn>usage scope validation</dfn> by composing
the set of all [=usage flags=] of each [=subresource=] used in the [=usage scope=].
A {{GPUValidationError}} is generated in the current scope with an appropriate error message
if that union contains a [=mutating usage=] combined with any other usage.


## Core Internal Objects ## {#core-internal-objects}

### Adapters ### {#adapters}

An <dfn dfn>adapter</dfn> represents an implementation of WebGPU on the system.
Each adapter identifies both an instance of a hardware accelerator (e.g. GPU or CPU) and
an instance of a browser's implementation of WebGPU on top of that accelerator.

If an [=adapter=] becomes unavailable, it becomes [=invalid=].
Once invalid, it never becomes valid again.
Any [=devices=] on the adapter, and [=internal objects=] owned by those devices,
also become invalid.

Note:
An [=adapter=] may be a physical display adapter (GPU), but it could also be
a software renderer.
A returned [=adapter=] could refer to different physical adapters, or to
different browser codepaths or system drivers on the same physical adapters.
Applications can hold onto multiple [=adapters=] at once (via {{GPUAdapter}})
(even if some are [=invalid=]),
and two of these could refer to different instances of the same physical
configuration (e.g. if the GPU was reset or disconnected and reconnected).

An [=adapter=] has the following internal slots:

<dl dfn-type=attribute dfn-for=adapter>
    : <dfn>\[[extensions]]</dfn>, of type sequence<{{GPUExtensionName}}>, readonly
    ::
        The extensions which can be used to create devices on this adapter.

    : <dfn>\[[limits]]</dfn>, of type {{GPULimits}}, readonly
    ::
        The [=better|best=] limits which can be used to create devices on this adapter.

        Each adapter limit must be the same or [=better=] than its default value in {{GPULimits}}.
</dl>

[=Adapters=] are exposed via {{GPUAdapter}}.

### Devices ### {#devices}

A <dfn dfn>device</dfn> is the logical instantiation of an [=adapter=],
through which [=internal objects=] are created.
It can be shared across multiple [=agents=] (e.g. dedicated workers).

A [=device=] is the exclusive owner of all [=internal objects=] created from it:
when the [=device=] is lost, it and all objects created on it (directly, e.g.
{{GPUDevice/createTexture()}}, or indirectly, e.g. {{GPUTexture/createView()}}) become
[=invalid=].

Issue: Define "ownership".

A [=device=] has the following internal slots:

<dl dfn-type=attribute dfn-for=device>
    : <dfn>\[[adapter]]</dfn>, of type [=adapter=], readonly
    ::
        The [=adapter=] from which this device was created.

    : <dfn>\[[extensions]]</dfn>, of type sequence<{{GPUExtensionName}}>, readonly
    ::
        The extensions which can be used on this device.
        No additional extensions can be used, even if the underlying [=adapter=] can support them.

    : <dfn>\[[limits]]</dfn>, of type {{GPULimits}}, readonly
    ::
        The limits which can be used on this device.
        No [=better=] limits can be used, even if the underlying [=adapter=] can support them.
</dl>

<div algorithm>
    When <dfn dfn>a new device</dfn> |device| is created from [=adapter=] |adapter|
    with {{GPUDeviceDescriptor}} |descriptor|:

      - Set |device|.{{device/[[adapter]]}} to |adapter|.

      - Set |device|.{{device/[[extensions]]}} to |descriptor|.{{GPUDeviceDescriptor/extensions}}.

      - Set |device|.{{device/[[limits]]}} to |descriptor|.{{GPUDeviceDescriptor/limits}}.
</div>

[=Devices=] are exposed via {{GPUDevice}}.

## Optional Capabilities ## {#optional-capabilities}

### Limits ### {#limits}

### Extensions ### {#extensions}
